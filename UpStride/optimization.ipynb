{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "conscious-argentina",
   "metadata": {},
   "source": [
    "## Gradient Descent Algorithm\n",
    "Gradient Descent minimize the loss between objective and cost function by taking partial derivatives with respect to each parameter(w, b in this example)\n",
    "\n",
    "・Gradient \\\n",
    "$\\nabla L = (\\frac{\\partial L}{\\partial w} \\frac{\\partial L}{\\partial b})$\n",
    "\n",
    "・Partial Derivatives \\\n",
    "$\\frac{\\partial}{\\partial w}((y-(wx^2+b)) = -2x^2(-b-wx^2+y)$ \\\n",
    "$\\frac{\\partial}{\\partial b}((y-(wx^2+b)) = -2(-b-wx^2+y)$\n",
    "\n",
    "・Update parameters \\\n",
    "$w ← w - \\eta \\frac{\\partial f}{\\partial w} $ \\\n",
    "$b ← b - \\eta \\frac{\\partial f}{\\partial b} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fitted-gathering",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.626872156973847\n",
      "3.053735623602739\n",
      "2.0154655115778075\n",
      "1.330207237641353\n",
      "0.8779367768432929\n",
      "0.5794382727165733\n",
      "0.3824292599929383\n",
      "0.25240331159533924\n",
      "0.16658618565292388\n",
      "0.10994688253092977\n",
      "0.07256494247041367\n",
      "0.04789286203047294\n",
      "0.03160928894011217\n",
      "0.020862130700474046\n",
      "0.013769006262312922\n",
      "0.009087544133126513\n",
      "0.0059977791278635895\n",
      "0.003958534224389965\n",
      "0.0026126325880974077\n",
      "0.0017243375081443801\n",
      "0.001138062755375202\n",
      "0.0007511214185477177\n",
      "0.0004957401362415403\n",
      "0.0003271884899194166\n",
      "0.00021594440334682385\n",
      "0.00014252330620889708\n",
      "9.40653820978854e-05\n",
      "6.208315218458882e-05\n",
      "4.0974880441857486e-05\n",
      "2.7043421091610398e-05\n",
      "1.7848657920427335e-05\n",
      "1.1780114227533112e-05\n",
      "7.774875390165192e-06\n",
      "5.131417757597845e-06\n",
      "3.3867357199790504e-06\n",
      "2.2352455751883937e-06\n",
      "1.4752620796087967e-06\n",
      "9.736729725817739e-07\n",
      "6.42624161995009e-07\n",
      "4.2413194700774426e-07\n",
      "2.799270850672997e-07\n",
      "1.8475187613109512e-07\n",
      "1.2193623821765698e-07\n",
      "8.047791721921271e-08\n",
      "5.311542528030344e-08\n",
      "3.505618073607053e-08\n",
      "2.313707925249986e-08\n",
      "1.527047222005251e-08\n",
      "1.0078511580857707e-08\n",
      "6.651817652247871e-09\n",
      "4.390199648263149e-09\n",
      "2.8975317700741243e-09\n",
      "1.912370928280893e-09\n",
      "1.2621648171062816e-09\n",
      "8.330288681079878e-10\n",
      "5.497990951397469e-10\n",
      "3.6286740279223295e-10\n",
      "2.394925369131329e-10\n",
      "1.5806511655114264e-10\n",
      "1.0432299468732253e-10\n",
      "6.885314540738818e-11\n",
      "4.5443093732444595e-11\n",
      "2.999245296564368e-11\n",
      "1.9795054484461616e-11\n",
      "1.3064771486881455e-11\n",
      "8.62265814305374e-12\n",
      "5.6910032242285524e-12\n",
      "3.75610653691183e-12\n",
      "2.479016991685512e-12\n",
      "1.6361356713900932e-12\n",
      "1.0798029137504273e-12\n",
      "7.12652159506888e-13\n",
      "4.704014955336788e-13\n",
      "3.1041835768519377e-13\n",
      "2.0483614804334138e-13\n",
      "1.3522516439934407e-13\n",
      "8.926193117986259e-14\n",
      "5.895284260759581e-14\n",
      "3.885780586188048e-14\n",
      "2.5646151868841116e-14\n",
      "1.687538997430238e-14\n",
      "1.1102230246251565e-14\n",
      "7.327471962526033e-15\n",
      "4.884981308350689e-15\n",
      "3.219646771412954e-15\n",
      "2.1094237467877974e-15\n",
      "1.4432899320127035e-15\n",
      "9.992007221626409e-16\n",
      "6.661338147750939e-16\n",
      "4.440892098500626e-16\n",
      "3.3306690738754696e-16\n",
      "2.220446049250313e-16\n",
      "1.1102230246251565e-16\n",
      "1.1102230246251565e-16\n",
      "1.1102230246251565e-16\n",
      "1.1102230246251565e-16\n",
      "1.1102230246251565e-16\n",
      "1.1102230246251565e-16\n",
      "1.1102230246251565e-16\n",
      "1.1102230246251565e-16\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Cost function\n",
    "def nn(w,x,b):\n",
    "    return w*(x**2) + b\n",
    "\n",
    "w = random.random()\n",
    "b = random.random()\n",
    "lr = 0.01\n",
    "\n",
    "x = 2\n",
    "y = 0\n",
    "\n",
    "def update_params():\n",
    "    global w, b\n",
    "    y_pred = nn(w,x,b)\n",
    "    print(y_pred)\n",
    "    derivative_wrt_w = -2*x**2*(y - y_pred) # partial derivative\n",
    "    derivative_wrt_b = -2*(y - y_pred) # partial derivative\n",
    "    w = w - lr*derivative_wrt_w # Update w\n",
    "    b = b - lr*derivative_wrt_b # Update b\n",
    "\n",
    "for i in range(100):\n",
    "    update_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adverse-defendant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon = 0.0000000000000001 # Threshold \n",
    "y_hat = nn(w,x,b) # prediction of y\n",
    "(y - y_hat) < epsilon # Check if the prediction is correct"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
