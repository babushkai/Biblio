{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dominant-jacket",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers, optimizers\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "equivalent-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test  = X_test.astype(\"float32\")\n",
    "\n",
    "(X_train, X_valid) = X_train[5000:], X_train[:5000]\n",
    "(y_train, y_valid) = y_train[5000:], y_train[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "swedish-tucson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train = (45000, 32, 32, 3)\n",
      "x_valid = (5000, 32, 32, 3)\n",
      "x_test = (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print('x_train =', X_train.shape)\n",
    "print('x_valid =', X_valid.shape)\n",
    "print('x_test =', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "educated-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "std = np.std(X_train,axis=(0,1,2,3))\n",
    "X_train = (X_train-mean)/(std+1e-7)\n",
    "X_valid = (X_valid-mean)/(std+1e-7)\n",
    "X_test = (X_test-mean)/(std+1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "encouraging-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train,num_classes)\n",
    "y_valid = np_utils.to_categorical(y_valid,num_classes)\n",
    "y_test = np_utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "associate-category",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False)\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adolescent-smile",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 1e-4\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 1 - Conv\n",
    "model.add(Conv2D(32, (3,3), input_shape=(32,32,3),  padding='same',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Layer 2 - Conv\n",
    "model.add(Conv2D(32, (3,3), padding='same',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# MaxPool & Dropout\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Layer 3 - Conv\n",
    "model.add(Conv2D(64, (3,3), padding='same',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Layer 4 - Conv\n",
    "model.add(Conv2D(64, (3,3), padding='same',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# MaxPool & Dropout\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Layer 5 - Conv\n",
    "model.add(Conv2D(128, (3,3),  padding='same',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Layer 6 - Conv\n",
    "model.add(Conv2D(128, (3,3),  padding='same',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# MaxPool & Dropout\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# FC 7\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "exclusive-appreciation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/125\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.13756, saving model to model.100epochs.hdf5\n",
      "351/351 - 94s - loss: 1.8135 - accuracy: 0.4180 - val_loss: 2.1376 - val_accuracy: 0.3314\n",
      "Epoch 2/125\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.13756 to 1.31174, saving model to model.100epochs.hdf5\n",
      "351/351 - 96s - loss: 1.3074 - accuracy: 0.5606 - val_loss: 1.3117 - val_accuracy: 0.5994\n",
      "Epoch 3/125\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.31174 to 0.97897, saving model to model.100epochs.hdf5\n",
      "351/351 - 93s - loss: 1.1145 - accuracy: 0.6260 - val_loss: 0.9790 - val_accuracy: 0.6876\n",
      "Epoch 4/125\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.97897 to 0.91183, saving model to model.100epochs.hdf5\n",
      "351/351 - 96s - loss: 0.9765 - accuracy: 0.6738 - val_loss: 0.9118 - val_accuracy: 0.7142\n",
      "Epoch 5/125\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.91183 to 0.79410, saving model to model.100epochs.hdf5\n",
      "351/351 - 93s - loss: 0.8976 - accuracy: 0.7061 - val_loss: 0.7941 - val_accuracy: 0.7550\n",
      "Epoch 6/125\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.79410 to 0.77827, saving model to model.100epochs.hdf5\n",
      "351/351 - 94s - loss: 0.8384 - accuracy: 0.7260 - val_loss: 0.7783 - val_accuracy: 0.7686\n",
      "Epoch 7/125\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.77827 to 0.74511, saving model to model.100epochs.hdf5\n",
      "351/351 - 97s - loss: 0.7973 - accuracy: 0.7418 - val_loss: 0.7451 - val_accuracy: 0.7708\n",
      "Epoch 8/125\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.74511 to 0.68343, saving model to model.100epochs.hdf5\n",
      "351/351 - 111s - loss: 0.7642 - accuracy: 0.7554 - val_loss: 0.6834 - val_accuracy: 0.7906\n",
      "Epoch 9/125\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.68343\n",
      "351/351 - 97s - loss: 0.7370 - accuracy: 0.7650 - val_loss: 0.7195 - val_accuracy: 0.7864\n",
      "Epoch 10/125\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.68343\n",
      "351/351 - 96s - loss: 0.7114 - accuracy: 0.7764 - val_loss: 0.7167 - val_accuracy: 0.7852\n",
      "Epoch 11/125\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.68343\n",
      "351/351 - 95s - loss: 0.6858 - accuracy: 0.7873 - val_loss: 0.6914 - val_accuracy: 0.7942\n",
      "Epoch 12/125\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.68343 to 0.61013, saving model to model.100epochs.hdf5\n",
      "351/351 - 104s - loss: 0.6724 - accuracy: 0.7914 - val_loss: 0.6101 - val_accuracy: 0.8212\n",
      "Epoch 13/125\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.61013\n",
      "351/351 - 100s - loss: 0.6629 - accuracy: 0.7980 - val_loss: 0.6245 - val_accuracy: 0.8186\n",
      "Epoch 14/125\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.61013 to 0.60048, saving model to model.100epochs.hdf5\n",
      "351/351 - 112s - loss: 0.6451 - accuracy: 0.8043 - val_loss: 0.6005 - val_accuracy: 0.8238\n",
      "Epoch 15/125\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.60048\n",
      "351/351 - 98s - loss: 0.6324 - accuracy: 0.8116 - val_loss: 0.6059 - val_accuracy: 0.8298\n",
      "Epoch 16/125\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.60048\n",
      "351/351 - 100s - loss: 0.6266 - accuracy: 0.8129 - val_loss: 0.6249 - val_accuracy: 0.8274\n",
      "Epoch 17/125\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.60048\n",
      "351/351 - 94s - loss: 0.6114 - accuracy: 0.8192 - val_loss: 0.6554 - val_accuracy: 0.8166\n",
      "Epoch 18/125\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.60048 to 0.58758, saving model to model.100epochs.hdf5\n",
      "351/351 - 95s - loss: 0.6034 - accuracy: 0.8248 - val_loss: 0.5876 - val_accuracy: 0.8338\n",
      "Epoch 19/125\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.58758 to 0.55044, saving model to model.100epochs.hdf5\n",
      "351/351 - 94s - loss: 0.5978 - accuracy: 0.8260 - val_loss: 0.5504 - val_accuracy: 0.8456\n",
      "Epoch 20/125\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.55044\n",
      "351/351 - 94s - loss: 0.5964 - accuracy: 0.8291 - val_loss: 0.5834 - val_accuracy: 0.8388\n",
      "Epoch 21/125\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.55044\n",
      "351/351 - 94s - loss: 0.5906 - accuracy: 0.8300 - val_loss: 0.5608 - val_accuracy: 0.8402\n",
      "Epoch 22/125\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.55044\n",
      "351/351 - 93s - loss: 0.5806 - accuracy: 0.8359 - val_loss: 0.5994 - val_accuracy: 0.8366\n",
      "Epoch 23/125\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.55044\n",
      "351/351 - 94s - loss: 0.5760 - accuracy: 0.8353 - val_loss: 0.5544 - val_accuracy: 0.8498\n",
      "Epoch 24/125\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.55044\n",
      "351/351 - 94s - loss: 0.5693 - accuracy: 0.8394 - val_loss: 0.6150 - val_accuracy: 0.8356\n",
      "Epoch 25/125\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.55044\n",
      "351/351 - 92s - loss: 0.5669 - accuracy: 0.8420 - val_loss: 0.5744 - val_accuracy: 0.8506\n",
      "Epoch 26/125\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.55044 to 0.54848, saving model to model.100epochs.hdf5\n",
      "351/351 - 92s - loss: 0.5600 - accuracy: 0.8440 - val_loss: 0.5485 - val_accuracy: 0.8548\n",
      "Epoch 27/125\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.54848\n",
      "351/351 - 92s - loss: 0.5506 - accuracy: 0.8499 - val_loss: 0.5834 - val_accuracy: 0.8444\n",
      "Epoch 28/125\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.54848\n",
      "351/351 - 92s - loss: 0.5526 - accuracy: 0.8496 - val_loss: 0.5652 - val_accuracy: 0.8532\n",
      "Epoch 29/125\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.54848\n",
      "351/351 - 92s - loss: 0.5462 - accuracy: 0.8510 - val_loss: 0.5805 - val_accuracy: 0.8460\n",
      "Epoch 30/125\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.54848\n",
      "351/351 - 93s - loss: 0.5437 - accuracy: 0.8545 - val_loss: 0.5952 - val_accuracy: 0.8436\n",
      "Epoch 31/125\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.54848\n",
      "351/351 - 92s - loss: 0.5433 - accuracy: 0.8527 - val_loss: 0.5945 - val_accuracy: 0.8432\n",
      "Epoch 32/125\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.54848\n",
      "351/351 - 93s - loss: 0.5419 - accuracy: 0.8530 - val_loss: 0.5503 - val_accuracy: 0.8586\n",
      "Epoch 33/125\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.54848\n",
      "351/351 - 93s - loss: 0.5369 - accuracy: 0.8569 - val_loss: 0.6078 - val_accuracy: 0.8416\n",
      "Epoch 34/125\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.54848 to 0.52339, saving model to model.100epochs.hdf5\n",
      "351/351 - 92s - loss: 0.5336 - accuracy: 0.8586 - val_loss: 0.5234 - val_accuracy: 0.8654\n",
      "Epoch 35/125\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.52339\n",
      "351/351 - 92s - loss: 0.5269 - accuracy: 0.8621 - val_loss: 0.5382 - val_accuracy: 0.8626\n",
      "Epoch 36/125\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.52339\n",
      "351/351 - 92s - loss: 0.5263 - accuracy: 0.8609 - val_loss: 0.5809 - val_accuracy: 0.8542\n",
      "Epoch 37/125\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.52339\n",
      "351/351 - 93s - loss: 0.5264 - accuracy: 0.8618 - val_loss: 0.5690 - val_accuracy: 0.8538\n",
      "Epoch 38/125\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.52339\n",
      "351/351 - 93s - loss: 0.5257 - accuracy: 0.8621 - val_loss: 0.5707 - val_accuracy: 0.8568\n",
      "Epoch 39/125\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.52339\n",
      "351/351 - 94s - loss: 0.5236 - accuracy: 0.8635 - val_loss: 0.5520 - val_accuracy: 0.8600\n",
      "Epoch 40/125\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.52339\n",
      "351/351 - 92s - loss: 0.5193 - accuracy: 0.8662 - val_loss: 0.5372 - val_accuracy: 0.8672\n",
      "Epoch 41/125\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.52339\n",
      "351/351 - 92s - loss: 0.5209 - accuracy: 0.8650 - val_loss: 0.5431 - val_accuracy: 0.8640\n",
      "Epoch 42/125\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.52339\n",
      "351/351 - 93s - loss: 0.5163 - accuracy: 0.8677 - val_loss: 0.5812 - val_accuracy: 0.8546\n",
      "Epoch 43/125\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.52339\n",
      "351/351 - 94s - loss: 0.5140 - accuracy: 0.8670 - val_loss: 0.5512 - val_accuracy: 0.8628\n",
      "Epoch 44/125\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.52339\n",
      "351/351 - 93s - loss: 0.5124 - accuracy: 0.8701 - val_loss: 0.5401 - val_accuracy: 0.8656\n",
      "Epoch 45/125\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.52339 to 0.51881, saving model to model.100epochs.hdf5\n",
      "351/351 - 97s - loss: 0.5115 - accuracy: 0.8697 - val_loss: 0.5188 - val_accuracy: 0.8760\n",
      "Epoch 46/125\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.51881\n",
      "351/351 - 95s - loss: 0.5080 - accuracy: 0.8710 - val_loss: 0.6005 - val_accuracy: 0.8520\n",
      "Epoch 47/125\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.51881\n",
      "351/351 - 96s - loss: 0.5063 - accuracy: 0.8715 - val_loss: 0.5663 - val_accuracy: 0.8586\n",
      "Epoch 48/125\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.51881\n",
      "351/351 - 95s - loss: 0.5097 - accuracy: 0.8724 - val_loss: 0.5407 - val_accuracy: 0.8692\n",
      "Epoch 49/125\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.51881\n",
      "351/351 - 94s - loss: 0.5074 - accuracy: 0.8724 - val_loss: 0.5665 - val_accuracy: 0.8632\n",
      "Epoch 50/125\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.51881\n",
      "351/351 - 95s - loss: 0.5006 - accuracy: 0.8751 - val_loss: 0.5863 - val_accuracy: 0.8560\n",
      "Epoch 51/125\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.51881\n",
      "351/351 - 94s - loss: 0.4975 - accuracy: 0.8771 - val_loss: 0.6098 - val_accuracy: 0.8548\n",
      "Epoch 52/125\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.51881\n",
      "351/351 - 94s - loss: 0.4989 - accuracy: 0.8747 - val_loss: 0.5806 - val_accuracy: 0.8594\n",
      "Epoch 53/125\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.51881\n",
      "351/351 - 93s - loss: 0.5029 - accuracy: 0.8750 - val_loss: 0.5261 - val_accuracy: 0.8744\n",
      "Epoch 54/125\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.51881\n",
      "351/351 - 93s - loss: 0.4988 - accuracy: 0.8772 - val_loss: 0.5827 - val_accuracy: 0.8578\n",
      "Epoch 55/125\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.51881\n",
      "351/351 - 93s - loss: 0.4969 - accuracy: 0.8764 - val_loss: 0.5322 - val_accuracy: 0.8704\n",
      "Epoch 56/125\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.51881\n",
      "351/351 - 94s - loss: 0.4941 - accuracy: 0.8771 - val_loss: 0.5363 - val_accuracy: 0.8722\n",
      "Epoch 57/125\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.51881\n",
      "351/351 - 93s - loss: 0.4978 - accuracy: 0.8754 - val_loss: 0.5558 - val_accuracy: 0.8626\n",
      "Epoch 58/125\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.51881\n",
      "351/351 - 93s - loss: 0.4980 - accuracy: 0.8762 - val_loss: 0.5534 - val_accuracy: 0.8668\n",
      "Epoch 59/125\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.51881 to 0.51739, saving model to model.100epochs.hdf5\n",
      "351/351 - 92s - loss: 0.4947 - accuracy: 0.8773 - val_loss: 0.5174 - val_accuracy: 0.8816\n",
      "Epoch 60/125\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.51739\n",
      "351/351 - 95s - loss: 0.4942 - accuracy: 0.8791 - val_loss: 0.5364 - val_accuracy: 0.8698\n",
      "Epoch 61/125\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.51739\n",
      "351/351 - 95s - loss: 0.4933 - accuracy: 0.8773 - val_loss: 0.5200 - val_accuracy: 0.8768\n",
      "Epoch 62/125\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.51739\n",
      "351/351 - 93s - loss: 0.4926 - accuracy: 0.8798 - val_loss: 0.5552 - val_accuracy: 0.8664\n",
      "Epoch 63/125\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.51739\n",
      "351/351 - 93s - loss: 0.4907 - accuracy: 0.8797 - val_loss: 0.5267 - val_accuracy: 0.8742\n",
      "Epoch 64/125\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.51739\n",
      "351/351 - 93s - loss: 0.4868 - accuracy: 0.8801 - val_loss: 0.5577 - val_accuracy: 0.8650\n",
      "Epoch 65/125\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.51739\n",
      "351/351 - 94s - loss: 0.4850 - accuracy: 0.8808 - val_loss: 0.5182 - val_accuracy: 0.8796\n",
      "Epoch 66/125\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.51739\n",
      "351/351 - 93s - loss: 0.4885 - accuracy: 0.8794 - val_loss: 0.5369 - val_accuracy: 0.8746\n",
      "Epoch 67/125\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.51739\n",
      "351/351 - 93s - loss: 0.4845 - accuracy: 0.8807 - val_loss: 0.5254 - val_accuracy: 0.8784\n",
      "Epoch 68/125\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.51739\n",
      "351/351 - 95s - loss: 0.4840 - accuracy: 0.8816 - val_loss: 0.5365 - val_accuracy: 0.8708\n",
      "Epoch 69/125\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.51739\n",
      "351/351 - 95s - loss: 0.4846 - accuracy: 0.8829 - val_loss: 0.5429 - val_accuracy: 0.8712\n",
      "Epoch 70/125\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.51739\n",
      "351/351 - 93s - loss: 0.4805 - accuracy: 0.8839 - val_loss: 0.5591 - val_accuracy: 0.8694\n",
      "Epoch 71/125\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.51739\n",
      "351/351 - 92s - loss: 0.4859 - accuracy: 0.8819 - val_loss: 0.5540 - val_accuracy: 0.8708\n",
      "Epoch 72/125\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.51739\n",
      "351/351 - 93s - loss: 0.4790 - accuracy: 0.8845 - val_loss: 0.5263 - val_accuracy: 0.8770\n",
      "Epoch 73/125\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.51739\n",
      "351/351 - 92s - loss: 0.4801 - accuracy: 0.8841 - val_loss: 0.5998 - val_accuracy: 0.8574\n",
      "Epoch 74/125\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.51739\n",
      "351/351 - 92s - loss: 0.4856 - accuracy: 0.8829 - val_loss: 0.5413 - val_accuracy: 0.8760\n",
      "Epoch 75/125\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.51739 to 0.51153, saving model to model.100epochs.hdf5\n",
      "351/351 - 94s - loss: 0.4780 - accuracy: 0.8859 - val_loss: 0.5115 - val_accuracy: 0.8786\n",
      "Epoch 76/125\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.51153\n",
      "351/351 - 93s - loss: 0.4739 - accuracy: 0.8852 - val_loss: 0.5212 - val_accuracy: 0.8780\n",
      "Epoch 77/125\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.51153\n",
      "351/351 - 93s - loss: 0.4775 - accuracy: 0.8853 - val_loss: 0.5285 - val_accuracy: 0.8772\n",
      "Epoch 78/125\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.51153 to 0.49955, saving model to model.100epochs.hdf5\n",
      "351/351 - 93s - loss: 0.4808 - accuracy: 0.8852 - val_loss: 0.4996 - val_accuracy: 0.8840\n",
      "Epoch 79/125\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.49955\n",
      "351/351 - 92s - loss: 0.4752 - accuracy: 0.8861 - val_loss: 0.5362 - val_accuracy: 0.8738\n",
      "Epoch 80/125\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.49955\n",
      "351/351 - 93s - loss: 0.4779 - accuracy: 0.8849 - val_loss: 0.6010 - val_accuracy: 0.8578\n",
      "Epoch 81/125\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.49955\n",
      "351/351 - 92s - loss: 0.4748 - accuracy: 0.8879 - val_loss: 0.5454 - val_accuracy: 0.8686\n",
      "Epoch 82/125\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.49955\n",
      "351/351 - 93s - loss: 0.4760 - accuracy: 0.8857 - val_loss: 0.5369 - val_accuracy: 0.8726\n",
      "Epoch 83/125\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.49955\n",
      "351/351 - 93s - loss: 0.4743 - accuracy: 0.8855 - val_loss: 0.5100 - val_accuracy: 0.8826\n",
      "Epoch 84/125\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.49955\n",
      "351/351 - 93s - loss: 0.4697 - accuracy: 0.8887 - val_loss: 0.5260 - val_accuracy: 0.8792\n",
      "Epoch 85/125\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.49955\n",
      "351/351 - 92s - loss: 0.4718 - accuracy: 0.8872 - val_loss: 0.5086 - val_accuracy: 0.8872\n",
      "Epoch 86/125\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.49955\n",
      "351/351 - 92s - loss: 0.4703 - accuracy: 0.8883 - val_loss: 0.5679 - val_accuracy: 0.8704\n",
      "Epoch 87/125\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.49955\n",
      "351/351 - 93s - loss: 0.4705 - accuracy: 0.8888 - val_loss: 0.5190 - val_accuracy: 0.8826\n",
      "Epoch 88/125\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.49955\n",
      "351/351 - 93s - loss: 0.4703 - accuracy: 0.8872 - val_loss: 0.5188 - val_accuracy: 0.8826\n",
      "Epoch 89/125\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.49955\n",
      "351/351 - 96s - loss: 0.4728 - accuracy: 0.8859 - val_loss: 0.5109 - val_accuracy: 0.8836\n",
      "Epoch 90/125\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.49955\n",
      "351/351 - 96s - loss: 0.4755 - accuracy: 0.8857 - val_loss: 0.5590 - val_accuracy: 0.8722\n",
      "Epoch 91/125\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.49955\n",
      "351/351 - 97s - loss: 0.4683 - accuracy: 0.8895 - val_loss: 0.5328 - val_accuracy: 0.8800\n",
      "Epoch 92/125\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.49955\n",
      "351/351 - 96s - loss: 0.4678 - accuracy: 0.8885 - val_loss: 0.5370 - val_accuracy: 0.8750\n",
      "Epoch 93/125\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.49955\n",
      "351/351 - 97s - loss: 0.4701 - accuracy: 0.8894 - val_loss: 0.5653 - val_accuracy: 0.8722\n",
      "Epoch 94/125\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.49955 to 0.49879, saving model to model.100epochs.hdf5\n",
      "351/351 - 96s - loss: 0.4756 - accuracy: 0.8875 - val_loss: 0.4988 - val_accuracy: 0.8874\n",
      "Epoch 95/125\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.49879\n",
      "351/351 - 96s - loss: 0.4704 - accuracy: 0.8879 - val_loss: 0.5416 - val_accuracy: 0.8756\n",
      "Epoch 96/125\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.49879\n",
      "351/351 - 96s - loss: 0.4718 - accuracy: 0.8892 - val_loss: 0.5008 - val_accuracy: 0.8856\n",
      "Epoch 97/125\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.49879\n",
      "351/351 - 95s - loss: 0.4674 - accuracy: 0.8898 - val_loss: 0.5643 - val_accuracy: 0.8714\n",
      "Epoch 98/125\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.49879\n",
      "351/351 - 96s - loss: 0.4698 - accuracy: 0.8893 - val_loss: 0.5047 - val_accuracy: 0.8800\n",
      "Epoch 99/125\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.49879\n",
      "351/351 - 95s - loss: 0.4638 - accuracy: 0.8901 - val_loss: 0.5324 - val_accuracy: 0.8794\n",
      "Epoch 100/125\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.49879\n",
      "351/351 - 96s - loss: 0.4675 - accuracy: 0.8895 - val_loss: 0.5325 - val_accuracy: 0.8778\n",
      "Epoch 101/125\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.49879\n",
      "351/351 - 96s - loss: 0.4667 - accuracy: 0.8899 - val_loss: 0.5555 - val_accuracy: 0.8736\n",
      "Epoch 102/125\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.49879\n",
      "351/351 - 94s - loss: 0.4668 - accuracy: 0.8898 - val_loss: 0.5106 - val_accuracy: 0.8876\n",
      "Epoch 103/125\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.49879 to 0.49593, saving model to model.100epochs.hdf5\n",
      "351/351 - 95s - loss: 0.4658 - accuracy: 0.8904 - val_loss: 0.4959 - val_accuracy: 0.8898\n",
      "Epoch 104/125\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.49593\n",
      "351/351 - 96s - loss: 0.4668 - accuracy: 0.8916 - val_loss: 0.5161 - val_accuracy: 0.8826\n",
      "Epoch 105/125\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.49593\n",
      "351/351 - 93s - loss: 0.4595 - accuracy: 0.8930 - val_loss: 0.4984 - val_accuracy: 0.8912\n",
      "Epoch 106/125\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.49593\n",
      "351/351 - 92s - loss: 0.4673 - accuracy: 0.8914 - val_loss: 0.5778 - val_accuracy: 0.8658\n",
      "Epoch 107/125\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.49593\n",
      "351/351 - 95s - loss: 0.4631 - accuracy: 0.8908 - val_loss: 0.5379 - val_accuracy: 0.8818\n",
      "Epoch 108/125\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.49593\n",
      "351/351 - 95s - loss: 0.4593 - accuracy: 0.8937 - val_loss: 0.5083 - val_accuracy: 0.8868\n",
      "Epoch 109/125\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.49593\n",
      "351/351 - 96s - loss: 0.4661 - accuracy: 0.8902 - val_loss: 0.5099 - val_accuracy: 0.8832\n",
      "Epoch 110/125\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.49593\n",
      "351/351 - 95s - loss: 0.4599 - accuracy: 0.8924 - val_loss: 0.5152 - val_accuracy: 0.8882\n",
      "Epoch 111/125\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.49593\n",
      "351/351 - 95s - loss: 0.4640 - accuracy: 0.8901 - val_loss: 0.5192 - val_accuracy: 0.8828\n",
      "Epoch 112/125\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.49593\n",
      "351/351 - 95s - loss: 0.4610 - accuracy: 0.8923 - val_loss: 0.5098 - val_accuracy: 0.8848\n",
      "Epoch 113/125\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.49593\n",
      "351/351 - 96s - loss: 0.4593 - accuracy: 0.8930 - val_loss: 0.5377 - val_accuracy: 0.8786\n",
      "Epoch 114/125\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.49593\n",
      "351/351 - 96s - loss: 0.4642 - accuracy: 0.8909 - val_loss: 0.5308 - val_accuracy: 0.8764\n",
      "Epoch 115/125\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.49593 to 0.49462, saving model to model.100epochs.hdf5\n",
      "351/351 - 95s - loss: 0.4629 - accuracy: 0.8931 - val_loss: 0.4946 - val_accuracy: 0.8870\n",
      "Epoch 116/125\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.49462 to 0.48550, saving model to model.100epochs.hdf5\n",
      "351/351 - 95s - loss: 0.4605 - accuracy: 0.8918 - val_loss: 0.4855 - val_accuracy: 0.8928\n",
      "Epoch 117/125\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.48550 to 0.48541, saving model to model.100epochs.hdf5\n",
      "351/351 - 94s - loss: 0.4581 - accuracy: 0.8951 - val_loss: 0.4854 - val_accuracy: 0.8934\n",
      "Epoch 118/125\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.48541\n",
      "351/351 - 93s - loss: 0.4610 - accuracy: 0.8924 - val_loss: 0.5332 - val_accuracy: 0.8796\n",
      "Epoch 119/125\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.48541\n",
      "351/351 - 92s - loss: 0.4576 - accuracy: 0.8953 - val_loss: 0.5441 - val_accuracy: 0.8770\n",
      "Epoch 120/125\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.48541 to 0.47850, saving model to model.100epochs.hdf5\n",
      "351/351 - 93s - loss: 0.4601 - accuracy: 0.8931 - val_loss: 0.4785 - val_accuracy: 0.8926\n",
      "Epoch 121/125\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.47850\n",
      "351/351 - 92s - loss: 0.4579 - accuracy: 0.8933 - val_loss: 0.5069 - val_accuracy: 0.8922\n",
      "Epoch 122/125\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.47850\n",
      "351/351 - 92s - loss: 0.4604 - accuracy: 0.8938 - val_loss: 0.5331 - val_accuracy: 0.8768\n",
      "Epoch 123/125\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.47850\n",
      "351/351 - 92s - loss: 0.4581 - accuracy: 0.8933 - val_loss: 0.4915 - val_accuracy: 0.8902\n",
      "Epoch 124/125\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.47850\n",
      "351/351 - 92s - loss: 0.4524 - accuracy: 0.8946 - val_loss: 0.5218 - val_accuracy: 0.8814\n",
      "Epoch 125/125\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.47850\n",
      "351/351 - 92s - loss: 0.4637 - accuracy: 0.8924 - val_loss: 0.5005 - val_accuracy: 0.8876\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128                                                          \n",
    "epochs = 125                                                              \n",
    " \n",
    "checkpointer = ModelCheckpoint(filepath='model.100epochs.hdf5', verbose=1, \n",
    "                               save_best_only=True )                      \n",
    "#optimizer = keras.optimizers.adam(lr=0.0001,decay=1e-6)                   \n",
    " \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"Adam\",\n",
    "              metrics=['accuracy'])                                                \n",
    " \n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=batch_size), callbacks=[checkpointer], steps_per_epoch=X_train.shape[0] // batch_size, epochs=epochs, verbose=2, validation_data=(X_valid, y_valid))                   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
