{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DSTI_DL_Lab4_April2021 solution.ipynb","provenance":[{"file_id":"18PNzvAgv0ap-Km9OEMbdBb-oyckAU_Ti","timestamp":1584912032269},{"file_id":"1p487aIe4d5khbPqnmy0rZabXft_w49QW","timestamp":1571167290166}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"YXfVRw5p4YOo"},"source":["# Neural Network on GPU\n"]},{"cell_type":"markdown","metadata":{"id":"JT49HHnBMPTh"},"source":["\n","From Kaggle: \n","\"MNIST (\"Modified National Institute of Standards and Technology\") is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\"\n","\n","[Read more.](https://www.kaggle.com/c/digit-recognizer)\n","\n","\n","<a title=\"By Josef Steppan [CC BY-SA 4.0 (https://creativecommons.org/licenses/by-sa/4.0)], from Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:MnistExamples.png\"><img width=\"512\" alt=\"MnistExamples\" src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png\"/></a>"]},{"cell_type":"code","metadata":{"id":"jK-Iyt4NXJoU","executionInfo":{"status":"ok","timestamp":1618506153021,"user_tz":-120,"elapsed":824,"user":{"displayName":"Lionel Fillatre","photoUrl":"","userId":"14463393848879581998"}}},"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dsets \n"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oq6RJyDIOB-T"},"source":["## STEP 1: LOADING DATASET"]},{"cell_type":"code","metadata":{"id":"aL21SXchOBwe","executionInfo":{"status":"ok","timestamp":1618506153021,"user_tz":-120,"elapsed":818,"user":{"displayName":"Lionel Fillatre","photoUrl":"","userId":"14463393848879581998"}}},"source":["train_dataset = dsets.MNIST(root='./data', \n","                            train=True, \n","                            transform=transforms.ToTensor(),\n","                            download=True)\n","\n","test_dataset = dsets.MNIST(root='./data', \n","                           train=False, \n","                           transform=transforms.ToTensor())"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z_zuJQxSOKQt"},"source":["## STEP 2: MAKING DATASET ITERABLE"]},{"cell_type":"code","metadata":{"id":"7bGDbP1pL4XE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618506231763,"user_tz":-120,"elapsed":1457,"user":{"displayName":"Lionel Fillatre","photoUrl":"","userId":"14463393848879581998"}},"outputId":"73ac32d5-6479-431f-f724-cf7ee0591e0a"},"source":["batch_size = 100\n","n_iters = 1200 \n","num_epochs = n_iters / (len(train_dataset) / batch_size)\n","num_epochs = int(num_epochs)\n","\n","print(\"Number of epochs: \" + str(num_epochs))\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=batch_size, \n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=batch_size, \n","                                          shuffle=False)\n"],"execution_count":48,"outputs":[{"output_type":"stream","text":["Number of epochs: 2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_FEft3CQOQIR"},"source":["## STEP 3: CREATE MODEL CLASS"]},{"cell_type":"code","metadata":{"id":"ZbEJ-1aAL9d1","executionInfo":{"status":"ok","timestamp":1618506232388,"user_tz":-120,"elapsed":2065,"user":{"displayName":"Lionel Fillatre","photoUrl":"","userId":"14463393848879581998"}}},"source":["class CNNModel(nn.Module):\n","    def __init__(self):\n","        super(CNNModel, self).__init__()\n","\n","        # Convolution 1\n","        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0)\n","        self.relu1 = nn.ReLU()\n","\n","        # Max pool 1\n","        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n","\n","        # Convolution 2\n","        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0)\n","        self.relu2 = nn.ReLU()\n","\n","        # Max pool 2\n","        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n","\n","        # Fully connected 1 (readout)\n","        self.fc1 = nn.Linear(32 * 4 * 4, 10) \n","\n","    def forward(self, x):\n","        # Convolution 1\n","        out = self.cnn1(x)\n","        out = self.relu1(out)\n","\n","        # Max pool 1\n","        out = self.maxpool1(out)\n","\n","        # Convolution 2 \n","        out = self.cnn2(out)\n","        out = self.relu2(out)\n","\n","        # Max pool 2 \n","        out = self.maxpool2(out)\n","\n","        # Resize\n","        # Original size: (100, 32, 7, 7)\n","        # out.size(0): 100\n","        # New out size: (100, 32*7*7)\n","        out = out.view(out.size(0), -1)\n","\n","        # Linear function (readout)\n","        out = self.fc1(out)\n","\n","        return out\n","\n"],"execution_count":49,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W3owYgg2OWYw"},"source":["## STEP 4: INSTANTIATE MODEL CLASS"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PIoEPSn1O_uE","executionInfo":{"status":"ok","timestamp":1618506232388,"user_tz":-120,"elapsed":2061,"user":{"displayName":"Lionel Fillatre","photoUrl":"","userId":"14463393848879581998"}},"outputId":"2aa38332-8a2f-4ac6-d312-8f90e331c6c9"},"source":["# Number of CUDA devices\n","# The first device is always named \"cuda:0\"\n","# The second one is \"cuda:1\", etc.\n","print(torch.cuda.device_count())"],"execution_count":50,"outputs":[{"output_type":"stream","text":["1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6dqM6gd4MA2I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618506232389,"user_tz":-120,"elapsed":2055,"user":{"displayName":"Lionel Fillatre","photoUrl":"","userId":"14463393848879581998"}},"outputId":"37b55635-89a6-4dd8-babf-3f410a47762a"},"source":["model = CNNModel()\n","\n","####################################################################\n","#  USE GPU FOR MODEL                                               #\n","#  The model must be put on the GPU before declaring the optimizer #\n","####################################################################\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","#device = \"cpu\"\n","\n","model.to(device)\n","\n","\n","\n"],"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CNNModel(\n","  (cnn1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n","  (relu1): ReLU()\n","  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (cnn2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n","  (relu2): ReLU()\n","  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (fc1): Linear(in_features=512, out_features=10, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"markdown","metadata":{"id":"5ArDN205ObQG"},"source":["## STEP 5: INSTANTIATE LOSS CLASS"]},{"cell_type":"code","metadata":{"id":"YtqarS-WMC5S","executionInfo":{"status":"ok","timestamp":1618506232390,"user_tz":-120,"elapsed":2050,"user":{"displayName":"Lionel Fillatre","photoUrl":"","userId":"14463393848879581998"}}},"source":["criterion = nn.CrossEntropyLoss()\n","\n"],"execution_count":52,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QqikNfyhOe7o"},"source":["## STEP 6: INSTANTIATE OPTIMIZER CLASS"]},{"cell_type":"code","metadata":{"id":"1roaQQwYMFFj","executionInfo":{"status":"ok","timestamp":1618506232390,"user_tz":-120,"elapsed":2046,"user":{"displayName":"Lionel Fillatre","photoUrl":"","userId":"14463393848879581998"}}},"source":["learning_rate = 0.01\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n"],"execution_count":53,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z0A9mJ3d6-f8"},"source":["Function to compute the accuracy on the test set"]},{"cell_type":"markdown","metadata":{"id":"92Qc2Ypnc2iX"},"source":["### Question: modify the following code to exploit the GPU instead of the CPU"]},{"cell_type":"code","metadata":{"id":"Sv17qSuGO5x6","executionInfo":{"status":"ok","timestamp":1618506232391,"user_tz":-120,"elapsed":2043,"user":{"displayName":"Lionel Fillatre","photoUrl":"","userId":"14463393848879581998"}}},"source":["def test_model(test_loader, model, device):\n","  # Calculate Accuracy         \n","  correct = 0\n","  total = 0\n","  # Iterate through test dataset\n","  for images, labels in test_loader:\n","    #######################\n","    #  USE GPU FOR MODEL  #\n","    #######################\n","    images = images.to(device)\n","    labels = labels.to(device)\n","\n","    # Forward pass only to get logits/output\n","    outputs = model(images)\n","\n","    # Get predictions from the maximum value\n","    _, predicted = torch.max(outputs, 1)\n","\n","    # Total number of labels\n","    total += labels.size(0)\n","\n","    # Total correct predictions\n","    correct += (predicted == labels).sum()\n","\n","  accuracy = 100 * float(correct) / float(total)\n","    \n","  return accuracy"],"execution_count":54,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sgJWjmbnOhff"},"source":["## STEP 7: TRAIN THE MODEL"]},{"cell_type":"markdown","metadata":{"id":"SZh9Bryn-15o"},"source":["### Question: modify the following code to exploit the GPU instead of the CPU"]},{"cell_type":"code","metadata":{"id":"_ADmEX6UMINe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618506249892,"user_tz":-120,"elapsed":19527,"user":{"displayName":"Lionel Fillatre","photoUrl":"","userId":"14463393848879581998"}},"outputId":"fe7db5ab-e95a-4a7d-d1ee-bc0d0c634eb9"},"source":["%%time\n","# Time execution of a Python statement or expression.\n","# wall time is the actual time taken from the start of a computer program to the end\n","\n","iter = 0\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","\n","        #######################\n","        #  USE GPU FOR MODEL  #\n","        #######################\n","        # images = images.requires_grad_().to(device)\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # Clear gradients w.r.t. parameters\n","        optimizer.zero_grad()\n","\n","        # Forward pass to get output/logits\n","        outputs = model(images)\n","\n","        # Calculate Loss: softmax --> cross entropy loss\n","        loss = criterion(outputs, labels)\n","\n","        # Getting gradients w.r.t. parameters\n","        loss.backward()\n","\n","        # Updating parameters\n","        optimizer.step()\n","\n","        iter += 1\n","\n","        if iter % 500 == 0:\n","            # Calculate Accuracy on the test set        \n","            accuracy = test_model(test_loader, model, device)\n","\n","            # Print Loss\n","            print('Iteration: {}. Loss: {}. Accuracy on test set: {}'.format(iter, loss.item(), accuracy))"],"execution_count":55,"outputs":[{"output_type":"stream","text":["Iteration: 500. Loss: 0.356608510017395. Accuracy on test set: 88.24\n","Iteration: 1000. Loss: 0.3457084000110626. Accuracy on test set: 92.07\n","CPU times: user 16.9 s, sys: 210 ms, total: 17.1 s\n","Wall time: 17.1 s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ozPdNeJH-Tfq"},"source":["### Question: compare the wall time on GPU to the wall time on CPU"]},{"cell_type":"code","metadata":{"id":"mwshsSjE-rk_","executionInfo":{"status":"ok","timestamp":1618506249892,"user_tz":-120,"elapsed":19522,"user":{"displayName":"Lionel Fillatre","photoUrl":"","userId":"14463393848879581998"}}},"source":["# device = \"cpu\" # and run again the notebook"],"execution_count":56,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gekTtS1p_v2k"},"source":["### Question: increase the number of epoch until 5 to see if we can expect a better average accuracy"]},{"cell_type":"code","metadata":{"id":"QxUym9ODAAzA","executionInfo":{"status":"ok","timestamp":1618506249893,"user_tz":-120,"elapsed":19517,"user":{"displayName":"Lionel Fillatre","photoUrl":"","userId":"14463393848879581998"}}},"source":["# n_iters = 3000 # increase n_iters"],"execution_count":57,"outputs":[]}]}