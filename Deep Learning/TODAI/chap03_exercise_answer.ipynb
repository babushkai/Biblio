{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"chap03_exercise_answer.ipynb","provenance":[{"file_id":"16B_7EqMynLF5wxzm9vD5ZcC8i-dNjsav","timestamp":1618394670019}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"cells":[{"cell_type":"markdown","metadata":{"id":"XuR-Q0Bw4Kqu"},"source":["# 第2回講義 演習"]},{"cell_type":"code","metadata":{"id":"6AKBw3Tr4Kqx"},"source":["from sklearn.utils import shuffle\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","from keras.datasets import mnist\n","\n","import numpy as np\n","\n","np.random.seed(34)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hJvQUbTP4Kq5"},"source":["## 目次\n","\n","課題1. ロジスティック回帰の実装と学習 (OR)\n","1. シグモイド関数\n","2. データセットの設定と重みの定義\n","3. train関数とvalid関数\n","4. 学習\n","\n","課題2. ソフトマックス回帰の実装と学習 (MNIST)\n","1. ソフトマックス関数\n","2. データセットの設定と重みの定義\n","3. train関数とvalid関数\n","4. 学習"]},{"cell_type":"markdown","metadata":{"id":"quBPRwBf4Kq7"},"source":["## 課題1. ロジスティック回帰の実装と学習 (OR)"]},{"cell_type":"markdown","metadata":{"id":"awSlFgRA4Kq9"},"source":["### 1. シグモイド関数\n","$$\n","    \\sigma({\\bf x}) = \\frac{1}{1 + \\exp(-{\\bf x})} = \\frac{\\exp({\\bf x})}{1 + \\exp({\\bf x})}\n","$$"]},{"cell_type":"code","metadata":{"id":"SxGov-BfwsiS"},"source":["def sigmoid(x):\n","    # 単純な実装\n","    # return 1 / (1 + np.exp(-x))\n","    \n","    # expのoverflow対策を施した実装\n","    # x >=0 のとき sigmoid(x) = 1 / (1 + exp(-x))\n","    # x < 0 のとき sigmoid(x) = exp(x) / (1 + exp(x))\n","    return np.exp(np.minimum(x, 0)) / (1 + np.exp(- np.abs(x)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HAA-lvhz4KrF"},"source":["### 2. データセットの設定と重みの定義"]},{"cell_type":"code","metadata":{"id":"csITtDcr4KrG"},"source":["# ORのデータセット\n","x_train_or = np.array([[0, 1], [1, 0], [0, 0], [1, 1]])\n","y_train_or = np.array([[1], [1], [0], [1]])\n","x_valid_or, y_valid_or = x_train_or, y_train_or\n","x_test_or, y_test_or = x_train_or, y_train_or\n","\n","# 重み (入力の次元数: 2, 出力の次元数: 1)\n","W_or = np.random.uniform(low=-0.08, high=0.08, size=(2, 1)).astype('float32')\n","b_or = np.zeros(shape=(1,)).astype('float32')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7raMb3ts4KrL"},"source":["### 3. train関数とvalid関数"]},{"cell_type":"markdown","metadata":{"id":"mGygQ2Md4KrM"},"source":["#### 3.1. 目的関数（2クラス交差エントロピー誤差関数）\n","\n","$$ E ({\\bf x}, {\\bf y}; {\\bf W}, {\\bf b} ) =  -\\frac{1}{N}\\sum^N_{i=1} \\left[ {\\bf y}_i \\log {\\bf \\hat{y}}_i ({\\bf x}_i; {\\bf W}, {\\bf b}) + (1 - {\\bf y}_i) \\log \\{ 1 - {\\bf \\hat{y}}_i ({\\bf x}_i; {\\bf W}, {\\bf b}) \\}\\right] $$"]},{"cell_type":"markdown","metadata":{"id":"oNruNkKG4KrN"},"source":["#### 3.2. モデルの推論\n","$$\n","    {\\bf \\hat{y}}_i = \\sigma({\\bf W} {\\bf x}_i + {\\bf b})\n","$$"]},{"cell_type":"markdown","metadata":{"id":"UWW0Bsia4KrP"},"source":["#### 3.3. モデルの学習\n","\\begin{align*}\n","    \\delta_i &= {\\bf \\hat{y}}_i - {\\bf y}_i \\\\\n","    \\nabla_{\\bf W} E &= \\frac{1}{N}\\sum^N_{i=1}\\delta_i {\\bf x}^{\\mathrm{T}}_i \\\\\n","    \\nabla_{\\bf b} E &= \\frac{1}{N}\\sum^N_{i=1}\\delta_i  \\\\\n","    {\\bf W} &\\leftarrow {\\bf W} - \\epsilon \\nabla_{\\bf W} E \\\\\n","    {\\bf b} &\\leftarrow {\\bf b} - \\epsilon \\nabla_{\\bf b} E \\\\\n","\\end{align*}"]},{"cell_type":"code","metadata":{"id":"U0NNuvbS4KrQ"},"source":["# logの中身が0になるのを防ぐ\n","def np_log(x):\n","    return np.log(np.clip(a=x, a_min=1e-10, a_max=1e+10))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cAeoMirR4KrV"},"source":["def train_or(x, y, eps=1.0):\n","    \"\"\"\n","    :param x: np.ndarray, 入力データ, shape=(batch_size, 入力の次元数)\n","    :param y: np.ndarray, 教師ラベル, shape=(batch_size, 出力の次元数)\n","    :param eps: float, 学習率\n","    \"\"\"\n","    global W_or, b_or\n","    \n","    batch_size = x.shape[0]\n","    \n","    # 予測\n","    y_hat = sigmoid(np.matmul(x, W_or) + b_or) # shape: (batch_size, 出力の次元数)\n","    \n","    # 目的関数の評価\n","    cost = (- y * np_log(y_hat) - (1 - y) * np_log(1 - y_hat)).mean()\n","    delta = y_hat - y # shape: (batch_size, 出力の次元数)\n","    \n","    # パラメータの更新\n","    dW = np.matmul(x.T, delta) / batch_size # shape: (入力の次元数, 出力の次元数)\n","    db = np.matmul(np.ones(shape=(batch_size,)), delta) / batch_size # shape: (出力の次元数,)\n","    W_or -= eps * dW\n","    b_or -= eps * db\n","\n","    return cost\n","\n","def valid_or(x, y):\n","    y_hat = sigmoid(np.matmul(x, W_or) + b_or)\n","    cost = (- y * np_log(y_hat) - (1 - y) * np_log(1 - y_hat)).mean()\n","    return cost, y_hat"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LiuO_6B-4Krb"},"source":["### 4. 学習"]},{"cell_type":"code","metadata":{"id":"N0WM2juD4Kre"},"source":["for epoch in range(1000):\n","    x_train_or, y_train_or = shuffle(x_train_or, y_train_or)\n","    cost = train_or(x_train_or, y_train_or)\n","    cost, y_pred = valid_or(x_valid_or, y_valid_or)\n","\n","print(y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"44tdPsW34Krq"},"source":["## 課題2. ソフトマックス回帰の実装と学習 (MNIST)"]},{"cell_type":"markdown","metadata":{"id":"YEprLDMd4Krr"},"source":["### 1. ソフトマックス関数\n","$$\n","    \\mathrm{softmax}({\\bf x})_k = \\frac{\\exp({\\bf x}_k)}{\\sum^K_{k'=1} \\exp({\\bf x}_{k'})} \\hspace{10mm} \\text{for} \\, k=1,\\ldots, K\n","$$"]},{"cell_type":"code","metadata":{"id":"LJtPrgDX4Krs"},"source":["def softmax(x):\n","    x -= x.max(axis=1, keepdims=True) # expのoverflowを防ぐ\n","    x_exp = np.exp(x)\n","    return x_exp / np.sum(x_exp, axis=1, keepdims=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"52fR-55x4Krx"},"source":["### 2. データセットの設定と重みの定義"]},{"cell_type":"code","metadata":{"id":"UFxomfOd_gzI"},"source":["(x_mnist_1, y_mnist_1), (x_mnist_2, y_mnist_2) = mnist.load_data()\n","\n","x_mnist = np.r_[x_mnist_1, x_mnist_2]\n","y_mnist = np.r_[y_mnist_1, y_mnist_2]\n","\n","x_mnist = x_mnist.astype('float32') / 255.\n","y_mnist = np.eye(N=10)[y_mnist.astype('int32').flatten()]\n","\n","x_mnist=x_mnist.reshape(x_mnist.shape[0],-1)\n","\n","x_train_mnist, x_test_mnist, y_train_mnist, y_test_mnist = train_test_split(x_mnist, y_mnist, test_size=10000)\n","x_train_mnist, x_valid_mnist, y_train_mnist, y_valid_mnist = train_test_split(x_train_mnist, y_train_mnist, test_size=10000)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uPX8RF6H4Kr2"},"source":["# 重み (入力の次元数: 784, 出力の次元数: 10)\n","W_mnist = np.random.uniform(low=-0.08, high=0.08, size=(784, 10)).astype('float32')\n","b_mnist = np.zeros(shape=(10,)).astype('float32')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"80EOFI-n4Kr6"},"source":["### 3. train関数とvalid関数"]},{"cell_type":"markdown","metadata":{"id":"qVyNaUd-4Kr8"},"source":["#### 3.1. 目的関数（多クラス交差エントロピー誤差関数）\n","\n","$$ E ({\\bf x}, {\\bf y}; {\\bf W}, {\\bf b} ) =  -\\frac{1}{N}\\sum^N_{i=1} \\sum^K_{k=1} {\\bf y}_{i, k} \\log {\\bf \\hat{y}}_{i, k} ({\\bf x}_i; {\\bf W}, {\\bf b}) $$"]},{"cell_type":"markdown","metadata":{"id":"g6ZIHaLH4Kr9"},"source":["#### 3.2. モデルの推論\n","$$\n","    {\\bf \\hat{y}}_i = \\mathrm{softmax}({\\bf W}{\\bf x}_i + {\\bf b})\n","$$"]},{"cell_type":"markdown","metadata":{"id":"v65ew-Qs4Kr-"},"source":["#### 3.3. モデルの学習\n","\\begin{align*}\n","    \\delta_i &= {\\bf \\hat{y}}_i - {\\bf y}_i \\\\\n","    \\nabla_{\\bf W} E &= \\frac{1}{N}\\sum^N_{i=1}\\delta_i {\\bf x}^{\\mathrm{T}}_i \\\\\n","    \\nabla_{\\bf b} E &= \\frac{1}{N}\\sum^N_{i=1}\\delta_i  \\\\\n","    {\\bf W} &\\leftarrow {\\bf W} - \\epsilon \\nabla_{\\bf W} E \\\\\n","    {\\bf b} &\\leftarrow {\\bf b} - \\epsilon \\nabla_{\\bf b} E \\\\\n","\\end{align*}"]},{"cell_type":"code","metadata":{"id":"ems70ikO4KsA"},"source":["def train_mnist(x, y, eps=1.0):\n","    \"\"\"\n","    :param x: np.ndarray, 入力データ, shape=(batch_size, 入力の次元数)\n","    :param y: np.ndarray, 教師ラベル, shape=(batch_size, 出力の次元数)\n","    :param eps: float, 学習率\n","    \"\"\"\n","    global W_mnist, b_mnist\n","    \n","    batch_size = x.shape[0]\n","    \n","    # 予測\n","    y_hat = softmax(np.matmul(x, W_mnist) + b_mnist) # shape: (batch_size, 出力の次元数)\n","    \n","    # 目的関数の評価\n","    cost = (- y * np_log(y_hat)).sum(axis=1).mean()\n","    delta = y_hat - y # shape: (batch_size, 出力の次元数)\n","    \n","    # パラメータの更新\n","    dW = np.matmul(x.T, delta) / batch_size # shape: (入力の次元数, 出力の次元数)\n","    db = np.matmul(np.ones(shape=(batch_size,)), delta) / batch_size # shape: (出力の次元数,)\n","    W_mnist -= eps * dW\n","    b_mnist -= eps * db\n","\n","    return cost\n","\n","def valid_mnist(x, y):\n","    y_hat = softmax(np.matmul(x, W_mnist) + b_mnist)\n","    cost = (- y * np_log(y_hat)).sum(axis=1).mean()\n","    \n","    return cost, y_hat"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JBGInXhG4KsJ"},"source":["### 4. 学習"]},{"cell_type":"code","metadata":{"id":"7NbmLU4A4KsN"},"source":["for epoch in range(100):\n","    x_train_mnist, y_train_mnist = shuffle(x_train_mnist, y_train_mnist)\n","    cost = train_mnist(x_train_mnist, y_train_mnist)\n","    cost, y_pred = valid_mnist(x_valid_mnist, y_valid_mnist)\n","    if epoch % 10 == 9 or epoch == 0:\n","        print('EPOCH: {}, Valid Cost: {:.3f}, Valid Accuracy: {:.3f}'.format(\n","            epoch + 1,\n","            cost,\n","            accuracy_score(y_valid_mnist.argmax(axis=1), y_pred.argmax(axis=1))\n","        ))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JD6YYa5iwsiZ"},"source":[""],"execution_count":null,"outputs":[]}]}