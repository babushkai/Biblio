{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"chap07_exercise_answer.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"JmBi3Gs1DmAb"},"source":["# 第5回講義 演習"]},{"cell_type":"markdown","metadata":{"id":"N0uz7ym4DmAh"},"source":["## 目次\n","\n","- 課題. 高度な画像認識の実装と学習\n","    1. CIFAR-10データセットの読み込みと可視化\n","    2. Data Augmentation\n","        - 2.1. Flipping (horizontally)\n","        - 2.2. Random cropping\n","    3. Preprocessing\n","        - 3.1. Global Contrast Normalization (GCN)\n","        - 3.2. Zero-phase Component Analysis (ZCA) Whitening\n","    4. Batch Normalization\n","    5. 畳み込みニューラルネットワーク(Convolutional Neural Networks)の実装と学習\n","        - 5.1. 各層クラスの実装\n","        - 5.2. 計-算グラフ構築 & パラメータの更新設定\n","        - 5.3. 学習\n","    6. Activationの可視化\n","        - 6.1. conv1\n","        - 6.2. conv2\n","        - 6.3. conv3\n","    7. torch.nn に含まれるlayer, Loss関数の利用\n","        - 7.1. ネットワークの実装\n","        - 7.2. 学習"]},{"cell_type":"markdown","metadata":{"id":"tmK0SbsGDmAk"},"source":["## 課題. 高度な画像認識の実装と学習"]},{"cell_type":"code","metadata":{"id":"ixuHuEtKDmAm"},"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.autograd as autograd\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms, models\n","\n","\n","import matplotlib.pyplot as plt\n","\n","from sklearn.utils import shuffle\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","rng = np.random.RandomState(1234)\n","random_state = 42\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oqh8ZtFYDmAs"},"source":["## 1. CIFAR-10データセットの読み込みと可視化"]},{"cell_type":"code","metadata":{"id":"2j6ZednrDmAt"},"source":["batch_size = 1  # 可視化の際に扱いやすくするために1とする。\n","\n","dataloader_train = torch.utils.data.DataLoader(\n","    datasets.CIFAR10('./data/cifar10', train=True, download=True, transform=transforms.ToTensor()),\n","    batch_size=batch_size,\n","    shuffle=False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cQ5UqHX3DmAx"},"source":["fig = plt.figure(figsize=(9, 15))\n","fig.subplots_adjust(left=0, right=1, bottom=0, top=0.5, hspace=0.05,\n","                    wspace=0.05)\n","\n","i = 0\n","for x, _ in dataloader_train:\n","    x = np.transpose(torch.squeeze(x).numpy(), (1, 2, 0))\n","    ax = fig.add_subplot(9, 9, i + 1, xticks=[], yticks=[])\n","    ax.imshow(x)\n","    i += 1\n","    if i >= 81:\n","        break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p8gzhe_QDmA1"},"source":["## 2. Data Augmentation"]},{"cell_type":"markdown","metadata":{"id":"7-jKY1qIDmA3"},"source":["- Flipping (horizontally)\n","- Random cropping\n","- ...\n","\n","PytorchではDataLoaderの変数transformに変換を設定することで、様々なData Augmentationを簡単に実装することができます。"]},{"cell_type":"markdown","metadata":{"id":"76ik6mwcDmA4"},"source":["### 2.1. Flipping (horizontally)"]},{"cell_type":"code","metadata":{"id":"0w4Q00l_DmA6"},"source":["transform = transforms.Compose([transforms.RandomHorizontalFlip(p=1.0),  # horizontally flipping\n","                                transforms.ToTensor()])\n","\n","dataloader_train_flip = torch.utils.data.DataLoader(\n","    datasets.CIFAR10('./data/cifar10', train=True, transform=transform),\n","    batch_size=batch_size,\n","    shuffle=False\n",")\n","\n","fig = plt.figure(figsize=(9, 15))\n","fig.subplots_adjust(left=0, right=1, bottom=0, top=0.5, hspace=0.05,\n","                    wspace=0.05)\n","\n","i = 0\n","for x, _ in dataloader_train_flip:\n","    x = np.transpose(torch.squeeze(x).numpy(), (1, 2, 0))\n","    ax = fig.add_subplot(9, 9, i + 1, xticks=[], yticks=[])\n","    ax.imshow(x)\n","    i += 1\n","    if i >= 81:\n","        break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hIyz8tuIDmA-"},"source":["### 2.2. Random cropping"]},{"cell_type":"markdown","metadata":{"id":"O2n2WcjrDmA_"},"source":["- サイズを同じにするために、拡大したあとcropping、paddingしてからcroppingなどの方法があります。\n","- cropは学習時に各バッチに対して行うことも多いです。\n","- 今回はDeep Residual Learning for Image Recognitionで使われた手法を実装します。"]},{"cell_type":"code","metadata":{"id":"x_I7l33ODmBB"},"source":["transform = transforms.Compose([transforms.RandomCrop(32, padding=(4, 4, 4, 4), padding_mode='constant'),  # random cropoing\n","                                transforms.ToTensor()])\n","\n","dataloader_train_crop = torch.utils.data.DataLoader(\n","    datasets.CIFAR10('./data/cifar10', train=True, transform=transform),\n","    batch_size=batch_size,\n","    shuffle=False\n",")\n","\n","fig = plt.figure(figsize=(9, 15))\n","fig.subplots_adjust(left=0, right=1, bottom=0, top=0.5, hspace=0.05,\n","                    wspace=0.05)\n","\n","i = 0\n","for x, _ in dataloader_train_crop:\n","    x = np.transpose(torch.squeeze(x).numpy(), (1, 2, 0))\n","    ax = fig.add_subplot(9, 9, i + 1, xticks=[], yticks=[])\n","    ax.imshow(x)\n","    i += 1\n","    if i >= 81:\n","        break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cguQMzK-DmBE"},"source":["## 3. Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"s95Lj0MhDmBG"},"source":["- Global Contrast Normalization (GCN)\n","- ZCA Whitening"]},{"cell_type":"markdown","metadata":{"id":"9ixCVk8_DmBK"},"source":["### 3.1. Global Contrast Normalization (GCN)"]},{"cell_type":"markdown","metadata":{"id":"-Z1mkKapDmBa"},"source":["$$ {\\bf x}^{norm} = \\frac{{\\bf x} - \\bar{{\\bf x}}}{\\sqrt{\\sigma_{{\\bf x}}}} $$"]},{"cell_type":"markdown","metadata":{"id":"Nj6nuWi5DmBl"},"source":["- 通常の標準化とは違い，画像ごとに行います。\n","- 可視化した際は（可視化に際してスケールを[0,1]化しているので）見た目に変化はない。"]},{"cell_type":"code","metadata":{"id":"dUATgTVZDmBp"},"source":["# 既存のGCNクラスは存在しないので、自作する.\n","class gcn():\n","    def __init__(self):\n","        pass\n","\n","    def __call__(self, x):\n","        mean = torch.mean(x)\n","        std = torch.std(x)\n","        return (x - mean)/(std + 10**(-6))  # 0除算を防ぐ\n","\n","\n","def deprocess(x):\n","    _min = np.min(x)\n","    _max = np.max(x)\n","    _x = (x - _min)/(_max - _min)\n","    return _x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FM5WsVRKDmCU"},"source":["GCN = gcn()\n","transform_GCN = transforms.Compose([transforms.ToTensor(),\n","                                    GCN])\n","\n","dataloader_train_gcn = torch.utils.data.DataLoader(\n","    datasets.CIFAR10('./data/cifar10', train=True, transform=transform_GCN),\n","    batch_size=batch_size,\n","    shuffle=False\n",")\n","\n","fig = plt.figure(figsize=(9, 15))\n","fig.subplots_adjust(left=0, right=1, bottom=0, top=0.5, hspace=0.05,\n","                    wspace=0.05)\n","\n","i = 0\n","for x, _ in dataloader_train_gcn:\n","    x = np.transpose(torch.squeeze(x).numpy(), (1, 2, 0))\n","    ax = fig.add_subplot(9, 9, i + 1, xticks=[], yticks=[])\n","    ax.imshow(deprocess(x))\n","    i += 1\n","    if i >= 81:\n","        break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Po-FnL2YDmCb"},"source":["### 3.2. Zero-phase Component Analysis (ZCA) Whitening"]},{"cell_type":"markdown","metadata":{"id":"DiYFFG18DmCd"},"source":["$$ {\\bf x}^{ZCA} = A(\\Lambda + \\epsilon I)^{-\\frac{1}{2}} A^{\\mathrm{T}} ({\\bf x} - \\bar{\\bf x}) $$"]},{"cell_type":"markdown","metadata":{"id":"z-8lt6CMDmCf"},"source":["- torch.symeig(対象行列用の固有値分解)を用いてZCAを実装しています。"]},{"cell_type":"code","metadata":{"id":"9DRcN1eBDmCi"},"source":["# ZCA白色化の実装\n","class ZCAWhitening():\n","    def __init__(self, epsilon=1e-4, device=\"cuda\"):  # 計算が重いのでGPUを用いる\n","        self.epsilon = epsilon\n","        self.device = device\n","\n","    def fit(self, images):  # 変換行列と平均をデータから計算\n","        x = images[0][0].reshape(1, -1)\n","        self.mean = torch.zeros([1, x.size()[1]]).to(self.device)\n","        con_matrix = torch.zeros([x.size()[1], x.size()[1]]).to(self.device)\n","        for i in range(len(images)):  # 各データについての平均を取る\n","            x = images[i][0].reshape(1, -1).to(self.device)\n","            self.mean += x / len(images)\n","            con_matrix += torch.mm(x.t(), x) / len(images)\n","            if i % 10000 == 0:\n","                print(\"{0}/{1}\".format(i, len(images)))\n","        con_matrix -= torch.mm(self.mean.t(), self.mean)\n","        E, V = torch.symeig(con_matrix, eigenvectors=True)  # 固有値分解\n","        self.ZCA_matrix = torch.mm(torch.mm(V, torch.diag((E.squeeze()+self.epsilon)**(-0.5))), V.t())\n","        print(\"completed!\")\n","\n","    def __call__(self, x):\n","        size = x.size()\n","        x = x.reshape(1, -1).to(self.device)\n","        x -= self.mean\n","        #print(x)\n","        x = torch.mm(x, self.ZCA_matrix.t())\n","        #print(x)\n","        x = x.reshape(tuple(size))\n","        x = x.to(\"cpu\")\n","        return x    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gh_jPFnfCGLv"},"source":["zca = ZCAWhitening()\n","images = datasets.CIFAR10('./data/cifar10', train=True, transform=transforms.ToTensor())\n","zca.fit(images)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-kMkst8nJR3u"},"source":["transform_zca = transforms.Compose([transforms.ToTensor(),\n","                                    zca])\n","\n","dataloader_train_zca = torch.utils.data.DataLoader(\n","    datasets.CIFAR10('./data/cifar10', train=True, transform=transform_zca),\n","    batch_size=batch_size,\n","    shuffle=False\n",")\n","\n","fig = plt.figure(figsize=(9, 15))\n","fig.subplots_adjust(left=0, right=1, bottom=0, top=0.5, hspace=0.05,\n","                    wspace=0.05)\n","\n","i = 0\n","for x, _ in dataloader_train_zca:\n","    x = np.transpose(torch.squeeze(x).numpy(), (1, 2, 0))\n","    ax = fig.add_subplot(9, 9, i + 1, xticks=[], yticks=[])\n","    ax.imshow(deprocess(x))\n","    i += 1\n","    if i >= 81:\n","        break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7NUaXp9tDmDC"},"source":["## 4. Batch Normalization"]},{"cell_type":"markdown","metadata":{"id":"m2afZ4RcDmDE"},"source":["![](https://standardfrancis.files.wordpress.com/2015/04/screenshot-from-2015-04-16-133436.png?w=1008)"]},{"cell_type":"code","metadata":{"id":"rl3XBo5ZDmDG"},"source":["class BatchNorm(nn.Module):\n","    def __init__(self, shape, epsilon=np.float32(1e-5)):\n","        super().__init__()\n","        self.gamma = nn.Parameter(torch.tensor(np.ones(shape, dtype='float32')))\n","        self.beta = nn.Parameter(torch.tensor(np.zeros(shape, dtype='float32')))\n","        self.epsilon = epsilon\n","\n","    def forward(self, x):\n","        mean = torch.mean(x, (0, 2, 3), keepdim=True)\n","        std = torch.std(x, (0, 2, 3), keepdim=True)\n","        x_normalized = (x - mean) / (std**2 + self.epsilon)**0.5\n","        return self.gamma * x_normalized + self.beta"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gVZ2C1uSDmDd"},"source":["## 5. 畳み込みニューラルネットワーク(Convolutional Neural Networks)の実装と学習"]},{"cell_type":"markdown","metadata":{"id":"ACf9-dGYDmDe"},"source":["### 5.1. 各層クラスの実装"]},{"cell_type":"markdown","metadata":{"id":"H1ZPlDpvDmDq"},"source":["#### 畳み込み層"]},{"cell_type":"code","metadata":{"id":"yI4uyLK-DmDt"},"source":["class Conv(nn.Module):\n","    def __init__(self, filter_shape, function=lambda x: x, stride=(1, 1), padding=0):\n","        super().__init__()\n","        # Heの初期値\n","        fan_in = filter_shape[1] * filter_shape[2] * filter_shape[3]\n","        # filter_shape: (出力チャンネル数)x(入力チャンネル数)x(縦の次元数)x(横の次元数)\n","        fan_out = filter_shape[0] * filter_shape[2] * filter_shape[3]\n","\n","        self.W = nn.Parameter(torch.tensor(rng.normal(\n","                        0,\n","                        np.sqrt(2/fan_in),\n","                        size=filter_shape\n","                    ).astype('float32')))\n","\n","        # バイアスはフィルタごとなので, 出力フィルタ数と同じ次元数\n","        self.b = nn.Parameter(torch.tensor(np.zeros((filter_shape[0]), dtype='float32')))\n","\n","        self.function = function\n","        self.stride = stride\n","        self.padding = padding\n","\n","    def forward(self, x):\n","        u = F.conv2d(x, self.W, bias=self.b, stride=self.stride, padding=self.padding)\n","        return self.function(u)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G_UZMBJeDmD2"},"source":["#### プーリング層"]},{"cell_type":"code","metadata":{"id":"FKFBLR0JDmD4"},"source":["class Pooling(nn.Module):\n","    def __init__(self, ksize=(2, 2), stride=(2, 2), padding=0):\n","        super().__init__()\n","        self.ksize = ksize\n","        self.stride = stride\n","        self.padding = padding\n","\n","    def forward(self, x):\n","        return F.avg_pool2d(x, kernel_size=self.ksize, stride=self.stride, padding=self.padding)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oN75LnwqDmD-"},"source":["#### 平滑化層（4次元->2次元）"]},{"cell_type":"code","metadata":{"id":"0Rif9aPkDmD_"},"source":["class Flatten(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x):\n","        return x.view(x.size()[0], -1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"reDPfp7sDmEa"},"source":["#### 全結合層"]},{"cell_type":"code","metadata":{"id":"561LKkIhDmEc"},"source":["class Dense(nn.Module):\n","    def __init__(self, in_dim, out_dim, function=lambda x: x):\n","        super().__init__()\n","        # He Initialization\n","        # in_dim: 入力の次元数、out_dim: 出力の次元数\n","               \n","        self.W = nn.Parameter(torch.tensor(rng.normal(\n","                        0,\n","                        np.sqrt(2/in_dim),\n","                        size=(in_dim, out_dim)\n","                    ).astype('float32')))\n","\n","        self.b = nn.Parameter(torch.tensor(np.zeros([out_dim]).astype('float32')))\n","        self.function = function\n","\n","    def forward(self, x):\n","        return self.function(torch.matmul(x, self.W) + self.b)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UY-RnxAsDmEk"},"source":["#### 活性化層"]},{"cell_type":"code","metadata":{"id":"xcT6nIC8DmEl"},"source":["class Activation(nn.Module):\n","    def __init__(self, function=lambda x: x):\n","        super().__init__()\n","        self.function = function\n","\n","    def __call__(self, x):\n","        return self.function(x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"xIU5IN4YDmFF"},"source":["### 5.2. ネットワークの構築&データローダーの定義"]},{"cell_type":"code","metadata":{"id":"jWYkx5nyDmFI"},"source":["# torch.log(0)によるnanを防ぐ\n","def torch_log(x):\n","    return torch.log(torch.clamp(x, min=1e-10))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3KNe16MClZJW"},"source":["conv_net = nn.Sequential(\n","    Conv((32, 3, 3, 3)),     # 32x32x3 -> 30x30x32\n","    BatchNorm((32, 30, 30)),\n","    Activation(F.relu),\n","    Pooling((2, 2)),                  # 30x30x32 -> 15x15x32\n","    Conv((64, 32, 3, 3)),     # 15x15x32 -> 13x13x64\n","    BatchNorm((64, 13, 13)),\n","    Activation(F.relu),\n","    Pooling((2, 2)),                 # 13x13x64 -> 6x6x64\n","    Conv((128, 64, 3, 3)),           # 6x6x64 -> 4x4x128\n","    BatchNorm((128, 4, 4)),\n","    Activation(F.relu),\n","    Pooling((2, 2)),                 # 4x4x128 -> 2x2x128\n","    Flatten(),\n","    Dense(2*2*128, 256, F.relu),\n","    Dense(256, 10)\n",")\n","\n","batch_size = 100\n","n_epochs = 5\n","lr = 0.01\n","device = 'cuda'\n","\n","conv_net.to(device)\n","optimizer = optim.Adam(conv_net.parameters(), lr=lr)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EhjcetjrzPGN"},"source":["データの読み込み"]},{"cell_type":"code","metadata":{"id":"v6_sdyOqoj_8"},"source":["trainval_dataset = datasets.CIFAR10('./data/cifar10', train=True, transform=transforms.ToTensor())\n","\n","#zcaを定義\n","zca = ZCAWhitening()\n","zca.fit(trainval_dataset)\n","\n","# 前処理を定義\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                zca])\n","\n","trainval_dataset = datasets.CIFAR10('./data/cifar10', train=True, transform=transform)\n","\n","# trainとvalidに分割\n","train_dataset, val_dataset = torch.utils.data.random_split(trainval_dataset, [len(trainval_dataset)-10000, 10000])\n","\n","dataloader_train = torch.utils.data.DataLoader(\n","    train_dataset,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","dataloader_valid = torch.utils.data.DataLoader(\n","    val_dataset,\n","    batch_size=batch_size,\n","    shuffle=True\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YOS467vqDmFX"},"source":["### 5.3. 学習"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"avSZ0JguDmFv"},"source":["for epoch in range(n_epochs):\n","    losses_train = []\n","    losses_valid = []\n","\n","    conv_net.train()\n","    n_train = 0\n","    acc_train = 0\n","    for x, t in dataloader_train:\n","        n_train += t.size()[0]\n","\n","        conv_net.zero_grad()  # 勾配の初期化\n","\n","        x = x.to(device)  # テンソルをGPUに移動\n","\n","        t_hot = torch.eye(10)[t]  # 正解ラベルをone-hot vector化\n","\n","        t = t.to(device)\n","        t_hot = t_hot.to(device)  # 正解ラベルとone-hot vectorをそれぞれGPUに移動\n","\n","        y = conv_net.forward(x)  # 順伝播\n","\n","        loss = -(t_hot*torch.log_softmax(y, dim=-1)).sum(axis=1).mean()  # 誤差(クロスエントロピー誤差関数)の計算\n","\n","        loss.backward()  # 誤差の逆伝播\n","\n","        optimizer.step()  # パラメータの更新\n","\n","        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n","\n","        acc_train += (pred == t).float().sum().item()\n","        losses_train.append(loss.tolist())\n","\n","    conv_net.eval()\n","    n_val = 0\n","    acc_val = 0\n","    for x, t in dataloader_valid:\n","        n_val += t.size()[0]\n","\n","        x = x.to(device)  # テンソルをGPUに移動\n","\n","        t_hot = torch.eye(10)[t]  # 正解ラベルをone-hot vector化\n","\n","        t = t.to(device)\n","        t_hot = t_hot.to(device)  # 正解ラベルとone-hot vectorをそれぞれGPUに移動\n","\n","        y = conv_net.forward(x)  # 順伝播\n","\n","        loss = -(t_hot*torch.log_softmax(y, dim=-1)).sum(axis=1).mean()  # 誤差(クロスエントロピー誤差関数)の計算\n","\n","        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n","\n","        acc_val += (pred == t).float().sum().item()\n","        losses_valid.append(loss.tolist())\n","\n","    print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]'.format(\n","        epoch,\n","        np.mean(losses_train),\n","        acc_train/n_train,\n","        np.mean(losses_valid),\n","        acc_val/n_val\n","    ))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cfAES-2gDmF4"},"source":["## 6. Activationの可視化"]},{"cell_type":"code","metadata":{"id":"vtz5spz6DmF5"},"source":["trainval = datasets.CIFAR10('./data/cifar10')\n","image_id = 919  # 表示させる画像を選択\n","sample_image = trainval[image_id][0]\n","plt.imshow(sample_image)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eQswJpLmDmGA"},"source":["def feature_map(image, output_layer):  # output_layer番目の層の特徴マップを出力する関数\n","    image = transform(image)\n","    image = conv_net[0:output_layer + 1](image.unsqueeze(0).to(device))\n","    return image\n","\n","\n","print(\"ネットワークの構造\")\n","print(conv_net)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zCse4fWgDmF-"},"source":["### 6.1. conv_1"]},{"cell_type":"code","metadata":{"id":"3zCSW5jvDmGG"},"source":["_output = feature_map(sample_image, 0).to(\"cpu\")\n","fig = plt.figure(figsize=(10, 10))\n","_output = np.transpose(torch.squeeze(_output).detach().numpy(), (1, 2, 0))\n","for i in range(3):\n","    ax = fig.add_subplot(1, 3, i+1, xticks=[], yticks=[])\n","    ax.imshow(deprocess(_output[:, :, i]), cmap='gray')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pHrcKYUiDmGQ"},"source":["### 6.2. conv_2"]},{"cell_type":"code","metadata":{"id":"TmDXQw5NDmGZ"},"source":["_output = feature_map(sample_image, 4).to(\"cpu\")\n","fig = plt.figure(figsize=(10, 10))\n","_output = np.transpose(torch.squeeze(_output).detach().numpy(), (1, 2, 0))\n","for i in range(3):\n","    ax = fig.add_subplot(1, 3, i+1, xticks=[], yticks=[])\n","    ax.imshow(deprocess(_output[:, :, i]), cmap='gray')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EfsXVwmfDmGf"},"source":["### 6.3. conv_3"]},{"cell_type":"code","metadata":{"id":"C0Bn_Iu5DmGl"},"source":["_output = feature_map(sample_image, 8).to(\"cpu\")\n","fig = plt.figure(figsize=(10, 10))\n","_output = np.transpose(torch.squeeze(_output).detach().numpy(), (1, 2, 0))\n","for i in range(3):\n","    ax = fig.add_subplot(1, 3, i+1, xticks=[], yticks=[])\n","    ax.imshow(deprocess(_output[:, :, i]), cmap='gray')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4Td7OG8MDmGw"},"source":["## 7. torch.nn に含まれるlayer, Loss関数の利用"]},{"cell_type":"markdown","metadata":{"id":"Tcu2Ov61DmGx"},"source":["これまで扱ってきたPytorchの実装では比較的低レベルなAPIを使用してきました。それは本講義ではアルゴリズムの実装にフォーカスするためです。\n","\n","しかしながら、実際にビジネスや研究で利用するときにはプリミティブな実装を一から書くのは手間になる場合もあります。そのような課題を解決するニーズに答え、Pytorchには高レベルなAPIも用意されています。その一つとして`torch.nn`に含まれるlayerやLoss関数があります。\n","\n","ここまでは`torch.nn.Module`クラスを継承して様々なlayerを定義してきましたが、実は`torch.nn`に主要なlayer, Loss関数は含まれています。\n","\n","ここでは、`torch.nn`に含まれるlayer, Loss関数を使って、課題5の畳み込みニューラルネットワークの実装を行ってみましょう。\n","\n","\n","なお、このような高レベルなAPIは簡単に実装できる反面、実装の柔軟性が落ちるという欠点もあります。場合によって使い分ける必要があります。\n","\n","`torch.nn`で使えるモジュールは以下のページで確認できます。\n","\n","[Module: torch.nn](https://pytorch.org/docs/stable/nn.html)"]},{"cell_type":"markdown","metadata":{"id":"iuHjRBP4tbR3"},"source":["一般的なレイヤーは一通り揃っています。"]},{"cell_type":"markdown","metadata":{"hidden":true,"id":"iPtoB6P1tQpA"},"source":["```python\n","# 線形層\n","nn.Linear(input_dim, output_dim)\n","\n","# 畳み込み層\n","nn.Conv1d(input_dim, output_dim, kernel_size)\n","\n","# LSTM\n","nn.LSTM(input_dim, hidden_dim, num_layers)\n","\n","...\n","```"]},{"cell_type":"markdown","metadata":{"hidden":true,"id":"UzmpKQWyRsqE"},"source":["一般的な誤差関数も一通り揃っています。"]},{"cell_type":"markdown","metadata":{"hidden":true,"id":"7z1fN-0yRsqG"},"source":["```python\n","# L1誤差\n","nn.L1Loss()\n","\n","# 平均二乗誤差\n","nn.MSELoss()\n","\n","# 交差エントロピー誤差\n","nn.CrossEntropyLoss()\n","\n","...\n","```"]},{"cell_type":"markdown","metadata":{"id":"LReXSf-FDmGz"},"source":["### 7.1. ネットワークの実装"]},{"cell_type":"code","metadata":{"id":"NWi9NDFJDmG4"},"source":["conv_net2 = nn.Sequential(\n","    nn.Conv2d(3, 32, 3),              # 32x32x3 -> 30x30x32\n","    nn.BatchNorm2d(32),\n","    nn.ReLU(),\n","    nn.AvgPool2d(2),                  # 30x30x32 -> 15x15x32\n","    nn.Conv2d(32, 64, 3),             # 15x15x32 -> 13x13x64\n","    nn.BatchNorm2d(64),\n","    nn.ReLU(),\n","    nn.AvgPool2d(2),                  # 13x13x64 -> 6x6x64\n","    nn.Conv2d(64, 128, 3),            # 6x6x64 -> 4x4x128\n","    nn.BatchNorm2d(128),\n","    nn.ReLU(),\n","    nn.AvgPool2d(2),                  # 4x4x128 -> 2x2x128\n","    nn.Flatten(),\n","    nn.Linear(2*2*128, 256),\n","    nn.ReLU(),\n","    nn.Linear(256, 10)\n",")\n","\n","\n","def init_weights(m):  # Heの初期化\n","    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n","        torch.nn.init.kaiming_normal_(m.weight)\n","        m.bias.data.fill_(0.0)\n","\n","\n","conv_net2.apply(init_weights)\n","\n","batch_size = 100\n","n_epochs = 5\n","lr = 0.01\n","device = 'cuda'\n","\n","conv_net2.to(device)\n","optimizer2 = optim.Adam(conv_net2.parameters(), lr=lr)\n","loss_function = nn.CrossEntropyLoss()  # nn.ClossEntropyLossは、出力のsoftmax変換と、正解ラベルのone-hot vector化の機能を持っている"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7HjAjfanycI5"},"source":["データの読み込み"]},{"cell_type":"code","metadata":{"id":"28QGzQzwwsxd"},"source":["trainval_dataset = datasets.CIFAR10('./data/cifar10', train=True, transform=transforms.ToTensor())\n","\n","#zcaを定義\n","zca = ZCAWhitening()\n","zca.fit(trainval_dataset)\n","\n","# 前処理を定義\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                zca])\n","\n","trainval_dataset = datasets.CIFAR10('./data/cifar10', train=True, transform=transform)\n","\n","# trainとvalidに分割\n","train_dataset, val_dataset = torch.utils.data.random_split(trainval_dataset, [len(trainval_dataset)-10000, 10000])\n","\n","dataloader_train = torch.utils.data.DataLoader(\n","    train_dataset,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","dataloader_valid = torch.utils.data.DataLoader(\n","    val_dataset,\n","    batch_size=batch_size,\n","    shuffle=True\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WCfYomQMDmG_"},"source":["### 7.2. 学習"]},{"cell_type":"code","metadata":{"id":"lGQ4S71ODmHA"},"source":["for epoch in range(n_epochs):\n","    losses_train = []\n","    losses_valid = []\n","\n","    conv_net2.train()\n","    n_train = 0\n","    acc_train = 0\n","    for x, t in dataloader_train:\n","        n_train += t.size()[0]\n","\n","        conv_net2.zero_grad()  # 勾配の初期化\n","\n","        x = x.to(device)  # テンソルをGPUに移動\n","        t = t.to(device)\n","\n","        y = conv_net2.forward(x)  # 順伝播\n","\n","        loss = loss_function(y, t)  # 誤差(クロスエントロピー誤差関数)の計算\n","\n","        loss.backward()  # 誤差の逆伝播\n","\n","        optimizer2.step()  # パラメータの更新\n","\n","        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n","\n","        acc_train += (pred == t).float().sum().item()\n","        losses_train.append(loss.tolist())\n","\n","    conv_net2.eval()\n","    n_val = 0\n","    acc_val = 0\n","    for x, t in dataloader_valid:\n","        n_val += t.size()[0]\n","\n","        x = x.to(device)  # テンソルをGPUに移動\n","        t = t.to(device)\n","\n","        y = conv_net2.forward(x)  # 順伝播\n","\n","        loss = loss_function(y, t)  # 誤差(クロスエントロピー誤差関数)の計算\n","\n","        pred = y.argmax(1)  # 最大値を取るラベルを予測ラベルとする\n","\n","        acc_val += (pred == t).float().sum().item()\n","        losses_valid.append(loss.tolist())\n","\n","    print('EPOCH: {}, Train [Loss: {:.3f}, Accuracy: {:.3f}], Valid [Loss: {:.3f}, Accuracy: {:.3f}]'.format(\n","        epoch,\n","        np.mean(losses_train),\n","        acc_train/n_train,\n","        np.mean(losses_valid),\n","        acc_val/n_val\n","    ))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IR9GAEff8R3k"},"source":[""],"execution_count":null,"outputs":[]}]}