{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f7196e2-debb-44d0-94bd-7d19a5e1fc4d",
   "metadata": {},
   "source": [
    "# Redbull Classification Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc448dd5-7e17-464e-8d82-808d3d48835a",
   "metadata": {},
   "source": [
    "### Reference\n",
    "\n",
    "https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/master/notebooks/official/pipelines/google_cloud_pipeline_components_model_train_upload_deploy.ipynb \\\n",
    "https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/self-paced-labs/vertex-ai/vertex-ai-qwikstart/lab_exercise.ipynb \\\n",
    "https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/master/notebooks/official/custom/sdk-custom-image-classification-batch.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e47ae141-ec2b-4a14-b116-1487655a8af5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /home/jupyter/.local/lib/python3.7/site-packages (1.5.0)\n",
      "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.26.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (1.31.2)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (21.0)\n",
      "Requirement already satisfied: proto-plus>=1.10.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (1.19.0)\n",
      "Requirement already satisfied: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform) (2.26.0)\n",
      "Requirement already satisfied: google-cloud-storage<2.0.0dev,>=1.32.0 in /home/jupyter/.local/lib/python3.7/site-packages (from google-cloud-aiplatform) (1.42.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (1.53.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (2.25.1)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (1.35.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (2021.1)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (3.18.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (58.0.4)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (1.38.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (4.2.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.0.3)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.0.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-cloud-aiplatform) (2.4.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform) (2.10)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Google Cloud Notebook\n",
    "if os.path.exists(\"/opt/deeplearning/metadata/env_version\"):\n",
    "    USER_FLAG = \"--user\"\n",
    "else:\n",
    "    USER_FLAG = \"\"\n",
    "\n",
    "! pip3 install --upgrade google-cloud-aiplatform $USER_FLAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f65af0ee-020a-4c23-aaeb-58dc4f2b3ab2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-storage in /home/jupyter/.local/lib/python3.7/site-packages (1.42.3)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (2.25.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (1.16.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (2.0.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (1.35.0)\n",
      "Requirement already satisfied: google-api-core<3.0dev,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (1.31.2)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (3.18.0)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage) (2.0.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<3.0dev,>=1.29.0->google-cloud-storage) (1.53.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core<3.0dev,>=1.29.0->google-cloud-storage) (21.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core<3.0dev,>=1.29.0->google-cloud-storage) (2021.1)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<3.0dev,>=1.29.0->google-cloud-storage) (58.0.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.7.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage) (1.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-api-core<3.0dev,>=1.29.0->google-cloud-storage) (2.4.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.6)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install -U google-cloud-storage $USER_FLAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc09442b-ac4b-441b-b487-a0affc893c0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter in /opt/conda/lib/python3.7/site-packages (1.0.0)\n",
      "Requirement already satisfied: kfp in /opt/conda/lib/python3.7/site-packages (1.8.3)\n",
      "Requirement already satisfied: google-cloud-pipeline-components in /opt/conda/lib/python3.7/site-packages (0.1.7)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.7/site-packages (from jupyter) (6.1.0)\n",
      "Requirement already satisfied: qtconsole in /opt/conda/lib/python3.7/site-packages (from jupyter) (5.1.1)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.7/site-packages (from jupyter) (6.4.4)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.7/site-packages (from jupyter) (7.6.5)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.7/site-packages (from jupyter) (6.4.1)\n",
      "Requirement already satisfied: jupyter-console in /opt/conda/lib/python3.7/site-packages (from jupyter) (6.4.0)\n",
      "Requirement already satisfied: Deprecated<2,>=1.2.7 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.2.13)\n",
      "Requirement already satisfied: pydantic<2,>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.8.2)\n",
      "Requirement already satisfied: protobuf<4,>=3.13.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.18.0)\n",
      "Requirement already satisfied: kfp-server-api<2.0.0,>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.7.0)\n",
      "Requirement already satisfied: click<8,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (7.1.2)\n",
      "Requirement already satisfied: typing-extensions<4,>=3.10.0.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.10.0.2)\n",
      "Requirement already satisfied: kfp-pipeline-spec<0.2.0,>=0.1.10 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.1.11)\n",
      "Requirement already satisfied: tabulate<1,>=0.8.6 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.8.9)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.35.0)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.7.3 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.11)\n",
      "Requirement already satisfied: cloudpickle<2,>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.6.0)\n",
      "Requirement already satisfied: strip-hints<1,>=0.1.8 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.1.10)\n",
      "Requirement already satisfied: PyYAML<6,>=5.3 in /opt/conda/lib/python3.7/site-packages (from kfp) (5.4.1)\n",
      "Requirement already satisfied: absl-py<=0.11,>=0.9 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.10.0)\n",
      "Requirement already satisfied: uritemplate<4,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.0.1)\n",
      "Requirement already satisfied: jsonschema<4,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.2.0)\n",
      "Requirement already satisfied: google-cloud-storage<2,>=1.20.0 in /home/jupyter/.local/lib/python3.7/site-packages (from kfp) (1.42.3)\n",
      "Requirement already satisfied: kubernetes<19,>=8.0.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (18.20.0)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.7.8 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.12.8)\n",
      "Requirement already satisfied: fire<1,>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.4.0)\n",
      "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.9.1)\n",
      "Requirement already satisfied: google-cloud-aiplatform>=1.4.0 in /home/jupyter/.local/lib/python3.7/site-packages (from google-cloud-pipeline-components) (1.5.0)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.26.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-pipeline-components) (1.31.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py<=0.11,>=0.9->kfp) (1.16.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from Deprecated<2,>=1.2.7->kfp) (1.12.1)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.7/site-packages (from fire<1,>=0.3.1->kfp) (1.1.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components) (2.25.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components) (1.53.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components) (21.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components) (2021.1)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components) (58.0.4)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.1.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.19.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (0.2.7)\n",
      "Requirement already satisfied: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform>=1.4.0->google-cloud-pipeline-components) (2.26.0)\n",
      "Requirement already satisfied: proto-plus>=1.10.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-aiplatform>=1.4.0->google-cloud-pipeline-components) (1.19.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components) (1.38.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform>=1.4.0->google-cloud-pipeline-components) (2.0.0)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform>=1.4.0->google-cloud-pipeline-components) (2.0.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform>=1.4.0->google-cloud-pipeline-components) (1.2.0)\n",
      "Requirement already satisfied: pyparsing<3,>=2.4.2 in /opt/conda/lib/python3.7/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client<2,>=1.7.8->kfp) (2.4.7)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp) (4.8.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp) (21.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp) (0.17.3)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.15 in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (1.26.6)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2021.5.30)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.7/site-packages (from kubernetes<19,>=8.0.0->kfp) (1.3.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from kubernetes<19,>=8.0.0->kfp) (0.57.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.1->kfp) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components) (4.0.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from strip-hints<1,>=0.1.8->kfp) (0.37.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->jsonschema<4,>=3.0.1->kfp) (3.5.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from ipykernel->jupyter) (0.2.0)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipykernel->jupyter) (6.1)\n",
      "Requirement already satisfied: traitlets<6.0,>=4.1.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel->jupyter) (5.1.0)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel->jupyter) (0.1.3)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel->jupyter) (1.4.1)\n",
      "Requirement already satisfied: argcomplete>=1.12.3 in /opt/conda/lib/python3.7/site-packages (from ipykernel->jupyter) (1.12.3)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel->jupyter) (7.0.3)\n",
      "Requirement already satisfied: ipython<8.0,>=7.23.1 in /opt/conda/lib/python3.7/site-packages (from ipykernel->jupyter) (7.27.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter) (0.18.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter) (5.1.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter) (0.7.5)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter) (2.10.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter) (3.0.20)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython<8.0,>=7.23.1->ipykernel->jupyter) (0.8.2)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.7/site-packages (from jupyter-client<8.0->ipykernel->jupyter) (22.3.0)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from jupyter-client<8.0->ipykernel->jupyter) (0.3)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.7/site-packages (from jupyter-client<8.0->ipykernel->jupyter) (1.5.1)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from jupyter-client<8.0->ipykernel->jupyter) (4.8.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython<8.0,>=7.23.1->ipykernel->jupyter) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.0,>=7.23.1->ipykernel->jupyter) (0.2.5)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets->jupyter) (3.5.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets->jupyter) (5.1.3)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets->jupyter) (1.0.2)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter) (20.1.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter) (2.11.3)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter) (0.11.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.7/site-packages (from notebook->jupyter) (0.12.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from argon2-cffi->notebook->jupyter) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2->notebook->jupyter) (1.1.1)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter) (0.5.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter) (0.5.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter) (1.5.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter) (0.1.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter) (0.8.4)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert->jupyter) (4.1.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: qtpy in /opt/conda/lib/python3.7/site-packages (from qtconsole->jupyter) (1.11.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib->kubernetes<19,>=8.0.0->kfp) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install $USER kfp google-cloud-pipeline-components --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ddfb9a-f9f6-481b-958d-cabee3040be8",
   "metadata": {},
   "source": [
    "### Restart the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d54c90fd-fa4a-4aae-bf00-a979a3d498f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13eb8e3d-8fcf-411f-9940-75a8149832b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFP SDK version: 1.8.3\n",
      "google_cloud_pipeline_components version: 0.1.7\n"
     ]
    }
   ],
   "source": [
    "! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "! python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fb34933-df16-4c6c-a725-d49903f2372e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID: uplifted-road-327005\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"\n",
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID:\", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0b06ecc-2c2d-46fa-84f5-57d81f85efce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "\u001b[1;33mWARNING:\u001b[0m You do not appear to have access to project [uplifted-road-327005] or it does not exist.\n"
     ]
    }
   ],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8ffd136-1f18-435c-839b-eebe8f93d2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION=\"asia-northeast1\" #Tokyo region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "973cbc15-1d78-4a76-a054-677dc64b6855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-02-06-0410\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y-%m-%d-%H-%M%S\")\n",
    "print(TIMESTAMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7cc01bc-4f53-4a48-b470-1d367cc9f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"gs://pipeline-\" + TIMESTAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a300c708-3653-4c30-be93-38db5d6dc3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://pipeline-2021-10-02-06-0410/...\n"
     ]
    }
   ],
   "source": [
    "! gsutil mb -l $REGION $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46f7c109-2187-4bc5-ad67-fadd4b4f9afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25495dd1-6f7c-43e8-8668-c96c12af4b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service Account: 567299754976-compute@developer.gserviceaccount.com\n"
     ]
    }
   ],
   "source": [
    "SERVICE_ACCOUNT = \"[your-service-account]\"\n",
    "\n",
    "if (\n",
    "    SERVICE_ACCOUNT == \"\"\n",
    "    or SERVICE_ACCOUNT is None\n",
    "    or SERVICE_ACCOUNT == \"[your-service-account]\"\n",
    "):\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = !gcloud auth list 2>/dev/null\n",
    "    SERVICE_ACCOUNT = \"567299754976-compute@developer.gserviceaccount.com\" #shell_output[2].strip()\n",
    "    print(\"Service Account:\", SERVICE_ACCOUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2c8a48a-af24-4a3b-8dbb-bae64c037fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectCreator $BUCKET_NAME\n",
    "\n",
    "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectViewer $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f092096c-bf6e-47dc-b2cf-f194e54440da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.cloud.aiplatform as aip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0a52d12-66f5-484c-86f8-f705fbdda8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_ROOT = \"{}/pipeline_root/redbull\".format(BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c741abe-a637-479a-9941-9cb93df3ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from kfp.v2.dsl import component\n",
    "from kfp.v2.google import experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9da0561-1cfa-44ec-9472-5fa4eeb395c9",
   "metadata": {},
   "source": [
    "### Generate required files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "192bcccc-97d5-4697-b851-1d0c1e2c469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the name of your model subdirectory you will write your model code to. It is already created in your lab directory.\n",
    "MODEL_NAME=\"inception-resnetv2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc1f219c-8fb2-4088-904d-9bdcff1a4125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/home/jupyter/\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b05018c-c8d5-4725-b071-04857bd18b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘inception-resnetv2’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir {MODEL_NAME} && cd {MODEL_NAME} && mkdir trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1832b552-d851-4daa-9c23-b8e3f215bb43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inception-resnetv2/trainer/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {MODEL_NAME}/trainer/model.py\n",
    "import os\n",
    "import logging\n",
    "import tempfile\n",
    "from google.cloud import storage\n",
    "from pathlib import Path\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from explainable_ai_sdk.metadata.tf.v2 import SavedModelMetadataBuilder\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "IMG_SIZE = (160, 160)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "\n",
    "def create_dataset(bucket_name, prefix):\n",
    "    \n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blobs = bucket.list_blobs(prefix=prefix)\n",
    "\n",
    "    for blob in blobs:\n",
    "        if blob.name.endswith(\"/\"):\n",
    "            continue\n",
    "        file_split = blob.name.split(\"/\")\n",
    "        directory = \"/\".join(file_split[0:-1])\n",
    "        Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "        blob.download_to_filename(blob.name)   \n",
    "    \n",
    "    train_dir = os.path.join(prefix, 'train')\n",
    "    validation_dir = os.path.join(prefix, 'validation')\n",
    "\n",
    "    \n",
    "    train_dataset = image_dataset_from_directory(train_dir,\n",
    "                                             shuffle=True,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             image_size=IMG_SIZE)\n",
    "    \n",
    "    validation_dataset = image_dataset_from_directory(validation_dir,\n",
    "                                                  shuffle=True,\n",
    "                                                  batch_size=BATCH_SIZE,\n",
    "                                                  image_size=IMG_SIZE)\n",
    "    \n",
    "    val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
    "    test_dataset = validation_dataset.take(val_batches // 4)\n",
    "    validation_dataset = validation_dataset.skip(val_batches // 4)\n",
    "    \n",
    "    print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\n",
    "    print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))\n",
    "\n",
    "    # Configure the dataset for performance\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "    train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return train_dataset, validation_dataset, test_dataset\n",
    "\n",
    "\n",
    "def build_model(hparams):\n",
    "    \"\"\"Build and compile a TensorFlow Keras InceptionResNetV2.\"\"\"\n",
    "    \n",
    "    # Data Augmentation\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "      tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "      tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    ])\n",
    "    \n",
    "    # Data Preprocessing\n",
    "    preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "    \n",
    "    # Base Model\n",
    "    base_model = tf.keras.applications.InceptionResNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "    \n",
    "    base_model.trainable = False #Free the convolutional base\n",
    "    \n",
    "    # Classification head\n",
    "    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "\n",
    "    # Prediction Layer\n",
    "    prediction_layer = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    \n",
    "    # Build by Keras Functional API\n",
    "    inputs = tf.keras.Input(shape=(160, 160, 3))\n",
    "    x = data_augmentation(inputs)\n",
    "    x = preprocess_input(x)\n",
    "    x = base_model(x, training=False)\n",
    "    x = global_average_layer(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    outputs = prediction_layer(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    base_learning_rate = 0.0001\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train_evaluate_explain_model(hparams):\n",
    "    \"\"\"Train, evaluate, explain TensorFlow Keras DNN Regressor.\n",
    "    Args:\n",
    "      hparams(dict): A dictionary containing model training arguments.\n",
    "    Returns:\n",
    "      history(tf.keras.callbacks.History): Keras callback that records training event history.\n",
    "    \"\"\"\n",
    "    \n",
    "    train_dataset, validation_dataset, test_dataset = create_dataset(hparams['bucket_name'], \n",
    "                                                                     hparams['prefix'])\n",
    "    \n",
    "    model = build_model(hparams)\n",
    "    logging.info(model.summary())\n",
    "    \n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=hparams['tensorboard-dir'],\n",
    "        histogram_freq=1)\n",
    "    \n",
    "    # Reduce overfitting and shorten training times.\n",
    "    earlystopping_callback = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "    \n",
    "    # Ensure your training job's resilience to VM restarts.\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath= hparams['checkpoint-dir'],\n",
    "        save_weights_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min')\n",
    "    \n",
    "    # Virtual epochs design pattern:\n",
    "    # https://medium.com/google-cloud/ml-design-pattern-3-virtual-epochs-f842296de730\n",
    "    TOTAL_TRAIN_EXAMPLES = int(hparams['stop-point'] * hparams['n-train-examples'])\n",
    "    STEPS_PER_EPOCH = (TOTAL_TRAIN_EXAMPLES // (hparams['batch-size']*hparams['n-checkpoints']))    \n",
    "    \n",
    "    \n",
    "    history = model.fit(train_dataset,\n",
    "                    validation_data=validation_dataset,\n",
    "                    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                    epochs=hparams['n-checkpoints'],\n",
    "                    callbacks=[[tensorboard_callback,\n",
    "                                    earlystopping_callback,\n",
    "                                    checkpoint_callback]])\n",
    "    \n",
    "    \n",
    "    logging.info(model.evaluate(test_dataset))\n",
    "    \n",
    "    # Create a temp directory to save intermediate TF SavedModel prior to Explainable metadata creation.\n",
    "    tmpdir = tempfile.mkdtemp()\n",
    "    \n",
    "    # Export Keras model in TensorFlow SavedModel format.\n",
    "    model.save(tmpdir)\n",
    "    \n",
    "    # Annotate and save TensorFlow SavedModel with Explainable metadata to GCS.\n",
    "    builder = SavedModelMetadataBuilder(tmpdir)\n",
    "    builder.save_model_with_metadata(hparams['model-dir'])\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc14181c-5ecf-4234-9e81-3c9d24e7662a",
   "metadata": {},
   "source": [
    "### `task.py` as an entrypoint to the custom ML model container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bd6b7d4-57dc-4b70-883d-42a20f47208c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inception-resnetv2/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {MODEL_NAME}/trainer/task.py\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from trainer import model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # Vertex custom container training args. These are set by Vertex AI during training but can also be overwritten.\n",
    "    parser.add_argument('--model-dir', dest='model-dir',\n",
    "                        default=os.environ['AIP_MODEL_DIR'], type=str, help='Model dir.')\n",
    "    parser.add_argument('--checkpoint-dir', dest='checkpoint-dir',\n",
    "                        default=os.environ['AIP_CHECKPOINT_DIR'], type=str, help='Checkpoint dir set during Vertex AI training.')    \n",
    "    parser.add_argument('--tensorboard-dir', dest='tensorboard-dir',\n",
    "                        default=os.environ['AIP_TENSORBOARD_LOG_DIR'], type=str, help='Tensorboard dir set during Vertex AI training.')    \n",
    "    parser.add_argument('--data-format', dest='data-format',\n",
    "                        default=os.environ['AIP_DATA_FORMAT'], type=str, help=\"Tabular data format set during Vertex AI training. E.g.'csv', 'bigquery'\")\n",
    "    parser.add_argument('--training-data-uri', dest='training-data-uri',\n",
    "                        default=os.environ['AIP_TRAINING_DATA_URI'], type=str, help='Training data GCS or BQ URI set during Vertex AI training.')\n",
    "    parser.add_argument('--validation-data-uri', dest='validation-data-uri',\n",
    "                        default=os.environ['AIP_VALIDATION_DATA_URI'], type=str, help='Validation data GCS or BQ URI set during Vertex AI training.')\n",
    "    parser.add_argument('--test-data-uri', dest='test-data-uri',\n",
    "                        default=os.environ['AIP_TEST_DATA_URI'], type=str, help='Test data GCS or BQ URI set during Vertex AI training.')\n",
    "    # Model training args.\n",
    "    parser.add_argument('--learning-rate', dest='learning-rate', default=0.001, type=float, help='Learning rate for optimizer.')\n",
    "    parser.add_argument('--dropout', dest='dropout', default=0.2, type=float, help='Float percentage of DNN nodes [0,1] to drop for regularization.')    \n",
    "    parser.add_argument('--batch-size', dest='batch-size', default=16, type=int, help='Number of examples during each training iteration.')    \n",
    "    parser.add_argument('--n-train-examples', dest='n-train-examples', default=2638, type=int, help='Number of examples to train on.')\n",
    "    parser.add_argument('--stop-point', dest='stop-point', default=10, type=int, help='Number of passes through the dataset during training to achieve convergence.')\n",
    "    parser.add_argument('--n-checkpoints', dest='n-checkpoints', default=10, type=int, help='Number of model checkpoints to save during training.')\n",
    "    \n",
    "    # Custom arguments\n",
    "    parser.add_argument('--bucket_name', dest='bucket_name',  default='image-classification-datasets', type=str)\n",
    "    parser.add_argument('--prefix', dest='prefix',  default='redbull', type=str)\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    hparams = args.__dict__\n",
    "\n",
    "    model.train_evaluate_explain_model(hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b9c1a5-c875-4278-926e-a80b85b05fa0",
   "metadata": {},
   "source": [
    "### Write a `Dockerfile` for the custom ML model container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "955f75ee-8fac-49eb-a2f7-ee2364fdbded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inception-resnetv2/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile {MODEL_NAME}/Dockerfile\n",
    "# Specifies base image and tag.\n",
    "# https://cloud.google.com/vertex-ai/docs/general/deep-learning\n",
    "# https://cloud.google.com/deep-learning-containers/docs/choosing-container\n",
    "FROM gcr.io/deeplearning-platform-release/tf2-cpu.2-3\n",
    "\n",
    "# Sets the container working directory.\n",
    "WORKDIR /root\n",
    "\n",
    "# Copies the requirements.txt into the container to reduce network calls.\n",
    "COPY requirements.txt .\n",
    "# Installs additional packages.\n",
    "RUN pip3 install -U -r requirements.txt\n",
    "\n",
    "# Copies the trainer code to the docker image.\n",
    "COPY . /trainer\n",
    "\n",
    "# Sets the container working directory.\n",
    "WORKDIR /trainer\n",
    "\n",
    "# Sets up the entry point to invoke the trainer.\n",
    "ENTRYPOINT [\"python\", \"-m\", \"trainer.task\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c58a022b-1868-4cd5-a36f-df39c973ee59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inception-resnetv2/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {MODEL_NAME}/requirements.txt\n",
    "explainable-ai-sdk==1.3.0\n",
    "tensorflow-io==0.15.0\n",
    "pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd011c2-fc08-46e0-8387-31a532db04e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Artifact Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bcbf80f-74aa-47de-8f41-b44729aaacb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTIFACT_REPOSITORY=\"redbull-pipeline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "822e7384-5ae6-4abf-9c0e-5bdaeac0674a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mERROR:\u001b[0m (gcloud.artifacts.repositories.create) ALREADY_EXISTS: the repository already exists\n"
     ]
    }
   ],
   "source": [
    "# Create an Artifact Repository using the gcloud CLI.\n",
    "!gcloud artifacts repositories create $ARTIFACT_REPOSITORY \\\n",
    "--repository-format=docker \\\n",
    "--location=$REGION \\\n",
    "--description=\"Artifact registry for ML custom training images for Redbull Classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f293c2f-a467-4408-8731-ce5f7cd37544",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME=\"inceptionresnet-pipeline\"\n",
    "IMAGE_TAG=\"latest\"\n",
    "IMAGE_URI=f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{ARTIFACT_REPOSITORY}/{IMAGE_NAME}:{IMAGE_TAG}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d8f9b86-6523-45b1-8083-3f6b5218c4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asia-northeast1-docker.pkg.dev/uplifted-road-327005/redbull-pipeline/inceptionresnet-pipeline:latest'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617ddd25-edb0-412c-b24d-27cf1e484f12",
   "metadata": {},
   "source": [
    "### Create `cloudbuild.yaml` instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b70954ad-e2d8-4837-b448-46d1d1db15aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudbuild_yaml = f\"\"\"steps:\n",
    "- name: 'gcr.io/cloud-builders/docker'\n",
    "  args: [ 'build', '-t', '{IMAGE_URI}', '.' ]\n",
    "images: \n",
    "- '{IMAGE_URI}'\"\"\"\n",
    "\n",
    "with open(f\"{MODEL_NAME}/cloudbuild.yaml\", \"w\") as fp:\n",
    "    fp.write(cloudbuild_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf80f05e-213a-4fec-b999-caed715117fe",
   "metadata": {},
   "source": [
    "### Build and submit the container image to Artifact Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bce457b-80db-4322-a747-ec2f1b70e73f",
   "metadata": {},
   "source": [
    "Image name must be the lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c756baf8-14f5-414d-af0d-59e5b76a3dae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 5 file(s) totalling 9.8 KiB before compression.\n",
      "Uploading tarball of [inception-resnetv2] to [gs://uplifted-road-327005_cloudbuild/source/1633154662.384953-173856a20cb64af39f3cbed6fdef75ab.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/uplifted-road-327005/locations/global/builds/91a20f73-c54e-42d9-bc27-66f22ba5f4bd].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/91a20f73-c54e-42d9-bc27-66f22ba5f4bd?project=567299754976].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"91a20f73-c54e-42d9-bc27-66f22ba5f4bd\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://uplifted-road-327005_cloudbuild/source/1633154662.384953-173856a20cb64af39f3cbed6fdef75ab.tgz#1633154662700964\n",
      "Copying gs://uplifted-road-327005_cloudbuild/source/1633154662.384953-173856a20cb64af39f3cbed6fdef75ab.tgz#1633154662700964...\n",
      "/ [1 files][  3.4 KiB/  3.4 KiB]                                                \n",
      "Operation completed over 1 objects/3.4 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  15.36kB\n",
      "Step 1/7 : FROM gcr.io/deeplearning-platform-release/tf2-cpu.2-3\n",
      "latest: Pulling from deeplearning-platform-release/tf2-cpu.2-3\n",
      "e4ca327ec0e7: Pulling fs layer\n",
      "d92f1b6ebc96: Pulling fs layer\n",
      "caf909099ad7: Pulling fs layer\n",
      "f2436a8b630b: Pulling fs layer\n",
      "4f4fb700ef54: Pulling fs layer\n",
      "2142b3064d0c: Pulling fs layer\n",
      "8a5701c6f2ce: Pulling fs layer\n",
      "3f8d66c569d3: Pulling fs layer\n",
      "09401fb91b32: Pulling fs layer\n",
      "99f814694728: Pulling fs layer\n",
      "ce0dab248284: Pulling fs layer\n",
      "3e47e6559d28: Pulling fs layer\n",
      "351fc3c444d6: Pulling fs layer\n",
      "12b1e84e616f: Pulling fs layer\n",
      "0fa9d14c1b75: Pulling fs layer\n",
      "03db6fc56e5d: Pulling fs layer\n",
      "eef13798a5e7: Pulling fs layer\n",
      "12335b1eecf1: Pulling fs layer\n",
      "cc840140ef8f: Pulling fs layer\n",
      "a79374fe7905: Pulling fs layer\n",
      "f2436a8b630b: Waiting\n",
      "4f4fb700ef54: Waiting\n",
      "2142b3064d0c: Waiting\n",
      "8a5701c6f2ce: Waiting\n",
      "3f8d66c569d3: Waiting\n",
      "09401fb91b32: Waiting\n",
      "99f814694728: Waiting\n",
      "ce0dab248284: Waiting\n",
      "3e47e6559d28: Waiting\n",
      "351fc3c444d6: Waiting\n",
      "12b1e84e616f: Waiting\n",
      "0fa9d14c1b75: Waiting\n",
      "03db6fc56e5d: Waiting\n",
      "eef13798a5e7: Waiting\n",
      "12335b1eecf1: Waiting\n",
      "cc840140ef8f: Waiting\n",
      "a79374fe7905: Waiting\n",
      "d92f1b6ebc96: Download complete\n",
      "e4ca327ec0e7: Download complete\n",
      "4f4fb700ef54: Verifying Checksum\n",
      "4f4fb700ef54: Download complete\n",
      "2142b3064d0c: Download complete\n",
      "f2436a8b630b: Verifying Checksum\n",
      "f2436a8b630b: Download complete\n",
      "3f8d66c569d3: Verifying Checksum\n",
      "3f8d66c569d3: Download complete\n",
      "09401fb91b32: Verifying Checksum\n",
      "09401fb91b32: Download complete\n",
      "99f814694728: Verifying Checksum\n",
      "99f814694728: Download complete\n",
      "ce0dab248284: Verifying Checksum\n",
      "ce0dab248284: Download complete\n",
      "3e47e6559d28: Verifying Checksum\n",
      "3e47e6559d28: Download complete\n",
      "351fc3c444d6: Download complete\n",
      "12b1e84e616f: Verifying Checksum\n",
      "12b1e84e616f: Download complete\n",
      "0fa9d14c1b75: Verifying Checksum\n",
      "0fa9d14c1b75: Download complete\n",
      "03db6fc56e5d: Verifying Checksum\n",
      "03db6fc56e5d: Download complete\n",
      "8a5701c6f2ce: Verifying Checksum\n",
      "8a5701c6f2ce: Download complete\n",
      "12335b1eecf1: Verifying Checksum\n",
      "12335b1eecf1: Download complete\n",
      "caf909099ad7: Verifying Checksum\n",
      "caf909099ad7: Download complete\n",
      "cc840140ef8f: Verifying Checksum\n",
      "cc840140ef8f: Download complete\n",
      "a79374fe7905: Verifying Checksum\n",
      "a79374fe7905: Download complete\n",
      "e4ca327ec0e7: Pull complete\n",
      "d92f1b6ebc96: Pull complete\n",
      "eef13798a5e7: Verifying Checksum\n",
      "eef13798a5e7: Download complete\n",
      "caf909099ad7: Pull complete\n",
      "f2436a8b630b: Pull complete\n",
      "4f4fb700ef54: Pull complete\n",
      "2142b3064d0c: Pull complete\n",
      "8a5701c6f2ce: Pull complete\n",
      "3f8d66c569d3: Pull complete\n",
      "09401fb91b32: Pull complete\n",
      "99f814694728: Pull complete\n",
      "ce0dab248284: Pull complete\n",
      "3e47e6559d28: Pull complete\n",
      "351fc3c444d6: Pull complete\n",
      "12b1e84e616f: Pull complete\n",
      "0fa9d14c1b75: Pull complete\n",
      "03db6fc56e5d: Pull complete\n",
      "eef13798a5e7: Pull complete\n",
      "12335b1eecf1: Pull complete\n",
      "cc840140ef8f: Pull complete\n",
      "a79374fe7905: Pull complete\n",
      "Digest: sha256:70cdcbd93e7f81a7d8aad39c70fe6d5e4c158fcb0a60e99f8f4727bd33cb0006\n",
      "Status: Downloaded newer image for gcr.io/deeplearning-platform-release/tf2-cpu.2-3:latest\n",
      " ---> 772764111242\n",
      "Step 2/7 : WORKDIR /root\n",
      " ---> Running in 33c1428747bd\n",
      "Removing intermediate container 33c1428747bd\n",
      " ---> 407cfbd0c570\n",
      "Step 3/7 : COPY requirements.txt .\n",
      " ---> bf6a454992e7\n",
      "Step 4/7 : RUN pip3 install -U -r requirements.txt\n",
      " ---> Running in 76acf8188b22\n",
      "Collecting explainable-ai-sdk==1.3.0\n",
      "  Downloading explainable_ai_sdk-1.3.0-py3-none-any.whl (120 kB)\n",
      "Requirement already satisfied: tensorflow-io==0.15.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (0.15.0)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (5.0.0)\n",
      "Requirement already satisfied: google.auth>=1.14.1 in /opt/conda/lib/python3.7/site-packages (from explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (1.35.0)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in /opt/conda/lib/python3.7/site-packages (from explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (3.4.3)\n",
      "Requirement already satisfied: xai-tabular-widget in /opt/conda/lib/python3.7/site-packages (from explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.1.0)\n",
      "Requirement already satisfied: tensorflow>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (2.3.4)\n",
      "Requirement already satisfied: ipython in /opt/conda/lib/python3.7/site-packages (from explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (7.27.0)\n",
      "Requirement already satisfied: requests>=2.5 in /opt/conda/lib/python3.7/site-packages (from explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (2.25.1)\n",
      "Requirement already satisfied: numpy>=1.7 in /opt/conda/lib/python3.7/site-packages (from explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (1.19.5)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google.auth>=1.14.1->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (58.0.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google.auth>=1.14.1->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google.auth>=1.14.1->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google.auth>=1.14.1->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (4.2.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google.auth>=1.14.1->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.2->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.2->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.2->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (8.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.2->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.2.2->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google.auth>=1.14.1->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.5->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.5->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.5->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.5->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (2021.5.30)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.15.0->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.10.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.15.0->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.15.0->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.37.0)\n",
      "Collecting numpy>=1.7\n",
      "  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.15.0->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (3.18.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.15.0->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (3.3.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.15.0->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (2.10.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.15.0->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (1.38.1)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.15.0->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.15.0->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (1.12.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.15.0->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.15.0->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (1.6.3)\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.15.0->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.3.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.15.0->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=1.15.0->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (1.1.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.15.0->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.15.0->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.15.0->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow>=1.15.0->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.4.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=1.15.0->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=1.15.0->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (4.8.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=1.15.0->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=1.15.0->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (3.10.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=1.15.0->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (3.5.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (3.0.20)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.7.5)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.7/site-packages (from ipython->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.1.3)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipython->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (5.1.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (5.1.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.18.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (2.10.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.8.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.2.5)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in /opt/conda/lib/python3.7/site-packages (from xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (7.6.5)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (1.0.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (3.5.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (6.4.1)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (5.1.3)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (1.4.1)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (6.1)\n",
      "Requirement already satisfied: argcomplete>=1.12.3 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (1.12.3)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (7.0.3)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.3)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.7/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (1.5.1)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (4.8.1)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.7/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (22.3.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (21.2.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.7/site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (6.4.4)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.11.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (2.11.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (1.8.0)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (20.1.0)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (6.1.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.7.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.8.4)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.5.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.1.2)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (4.1.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.5.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (0.5.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->xai-tabular-widget->explainable-ai-sdk==1.3.0->-r requirements.txt (line 1)) (21.0)\n",
      "Installing collected packages: numpy, explainable-ai-sdk\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: explainable-ai-sdk\n",
      "    Found existing installation: explainable-ai-sdk 1.3.2\n",
      "    Uninstalling explainable-ai-sdk-1.3.2:\n",
      "      Successfully uninstalled explainable-ai-sdk-1.3.2\n",
      "Successfully installed explainable-ai-sdk-1.3.0 numpy-1.18.5\n",
      "\u001b[91mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tfx-bsl 0.26.1 requires google-api-python-client<2,>=1.7.11, but you have google-api-python-client 2.22.0 which is incompatible.\n",
      "tfx-bsl 0.26.1 requires pyarrow<0.18,>=0.17, but you have pyarrow 5.0.0 which is incompatible.\n",
      "tensorflow-transform 0.26.0 requires pyarrow<0.18,>=0.17, but you have pyarrow 5.0.0 which is incompatible.\n",
      "tensorflow-probability 0.11.0 requires cloudpickle==1.3, but you have cloudpickle 2.0.0 which is incompatible.\n",
      "tensorflow-model-analysis 0.26.1 requires pyarrow<0.18,>=0.17, but you have pyarrow 5.0.0 which is incompatible.\n",
      "tensorflow-data-validation 0.26.1 requires joblib<0.15,>=0.12, but you have joblib 1.0.1 which is incompatible.\n",
      "tensorflow-data-validation 0.26.1 requires pyarrow<0.18,>=0.17, but you have pyarrow 5.0.0 which is incompatible.\n",
      "apache-beam 2.28.0 requires httplib2<0.18.0,>=0.8, but you have httplib2 0.19.1 which is incompatible.\n",
      "apache-beam 2.28.0 requires pyarrow<3.0.0,>=0.15.1, but you have pyarrow 5.0.0 which is incompatible.\n",
      "apache-beam 2.28.0 requires typing-extensions<3.8.0,>=3.7.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 76acf8188b22\n",
      " ---> 0b1824ea73a0\n",
      "Step 5/7 : COPY . /trainer\n",
      " ---> 642b822e1dfa\n",
      "Step 6/7 : WORKDIR /trainer\n",
      " ---> Running in 33e53a762178\n",
      "Removing intermediate container 33e53a762178\n",
      " ---> 85d1ba86b262\n",
      "Step 7/7 : ENTRYPOINT [\"python\", \"-m\", \"trainer.task\"]\n",
      " ---> Running in e1df4e4606b8\n",
      "Removing intermediate container e1df4e4606b8\n",
      " ---> 3e48fa941097\n",
      "Successfully built 3e48fa941097\n",
      "Successfully tagged asia-northeast1-docker.pkg.dev/uplifted-road-327005/redbull-pipeline/inceptionresnet-pipeline:latest\n",
      "PUSH\n",
      "Pushing asia-northeast1-docker.pkg.dev/uplifted-road-327005/redbull-pipeline/inceptionresnet-pipeline:latest\n",
      "The push refers to repository [asia-northeast1-docker.pkg.dev/uplifted-road-327005/redbull-pipeline/inceptionresnet-pipeline]\n",
      "643a34550c58: Preparing\n",
      "d821147b4680: Preparing\n",
      "a33dcd7cea70: Preparing\n",
      "fc8c35aa392d: Preparing\n",
      "e1fa52730200: Preparing\n",
      "38de8bb20de5: Preparing\n",
      "432df9e47017: Preparing\n",
      "d2f4b42995cf: Preparing\n",
      "fb81e5699636: Preparing\n",
      "4930ebb0a931: Preparing\n",
      "131ce3bb5d74: Preparing\n",
      "7659c32f59e4: Preparing\n",
      "85614aa64610: Preparing\n",
      "6f3c3f5b29db: Preparing\n",
      "b067ab39d28b: Preparing\n",
      "8ae6e3198a0c: Preparing\n",
      "5c2ad55d2779: Preparing\n",
      "675644f7a682: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "f22a37fa3c8c: Preparing\n",
      "60bb9a4914af: Preparing\n",
      "a68a3162c7c3: Preparing\n",
      "6babb56be259: Preparing\n",
      "38de8bb20de5: Waiting\n",
      "432df9e47017: Waiting\n",
      "d2f4b42995cf: Waiting\n",
      "fb81e5699636: Waiting\n",
      "4930ebb0a931: Waiting\n",
      "131ce3bb5d74: Waiting\n",
      "7659c32f59e4: Waiting\n",
      "85614aa64610: Waiting\n",
      "6f3c3f5b29db: Waiting\n",
      "b067ab39d28b: Waiting\n",
      "8ae6e3198a0c: Waiting\n",
      "5c2ad55d2779: Waiting\n",
      "675644f7a682: Waiting\n",
      "5f70bf18a086: Waiting\n",
      "f22a37fa3c8c: Waiting\n",
      "60bb9a4914af: Waiting\n",
      "a68a3162c7c3: Waiting\n",
      "6babb56be259: Waiting\n",
      "e1fa52730200: Layer already exists\n",
      "fc8c35aa392d: Layer already exists\n",
      "38de8bb20de5: Layer already exists\n",
      "432df9e47017: Layer already exists\n",
      "fb81e5699636: Layer already exists\n",
      "d2f4b42995cf: Layer already exists\n",
      "4930ebb0a931: Layer already exists\n",
      "131ce3bb5d74: Layer already exists\n",
      "643a34550c58: Pushed\n",
      "7659c32f59e4: Layer already exists\n",
      "85614aa64610: Layer already exists\n",
      "a33dcd7cea70: Pushed\n",
      "6f3c3f5b29db: Layer already exists\n",
      "b067ab39d28b: Layer already exists\n",
      "8ae6e3198a0c: Layer already exists\n",
      "5c2ad55d2779: Layer already exists\n",
      "675644f7a682: Layer already exists\n",
      "5f70bf18a086: Layer already exists\n",
      "f22a37fa3c8c: Layer already exists\n",
      "a68a3162c7c3: Layer already exists\n",
      "60bb9a4914af: Layer already exists\n",
      "6babb56be259: Layer already exists\n",
      "d821147b4680: Pushed\n",
      "latest: digest: sha256:1bd137d71e5bfe7608f4b8b572a64fc715729ab0b4a7d503373d89f25b8e946b size: 5132\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                              IMAGES                                                                                                   STATUS\n",
      "91a20f73-c54e-42d9-bc27-66f22ba5f4bd  2021-10-02T06:04:22+00:00  3M38S     gs://uplifted-road-327005_cloudbuild/source/1633154662.384953-173856a20cb64af39f3cbed6fdef75ab.tgz  asia-northeast1-docker.pkg.dev/uplifted-road-327005/redbull-pipeline/inceptionresnet-pipeline (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --timeout=20m --config {MODEL_NAME}/cloudbuild.yaml {MODEL_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eba288-dd42-4ed0-a03e-d1aaf594e0d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Initialize Vertex SDK for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fb3730c-8f1b-45c4-a2f8-5f3e23e96099",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_OUTPUT_DIR= f\"gs://{BUCKET_NAME}/vertex-custom-training-{MODEL_NAME}-{TIMESTAMP}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00f060c4-c3de-4047-8dd8-32e53b828973",
   "metadata": {},
   "outputs": [],
   "source": [
    "aip.init(project=PROJECT_ID, staging_bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12650fe9-7c1d-440f-92f6-94f7b9981f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component\n",
    "def initiate(input1: str):\n",
    "    print(\"training task: {}\".format(input1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d830582a-f099-4a65-b7f3-70df13d4a312",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hp_dict: str = '{\"num_hidden_layers\": 3, \"hidden_size\": 32, \"learning_rate\": 0.01, \"epochs\": 1, \"steps_per_epoch\": -1}'\n",
    "#data_dir: str = \"gs://aju-dev-demos-codelabs/bikes_weather/\"\n",
    "#TRAINER_ARGS = [\"--data-dir\", data_dir, \"--hptune-dict\", hp_dict]\n",
    "\n",
    "# create working dir to pass to job spec\n",
    "WORKING_DIR = f\"{PIPELINE_ROOT}/{TIMESTAMP}\"\n",
    "\n",
    "\n",
    "MODEL_DISPLAY_NAME = f\"train_deploy{TIMESTAMP}\"\n",
    "#print(TRAINER_ARGS, WORKING_DIR, MODEL_DISPLAY_NAME)\n",
    "\n",
    "\n",
    "@kfp.dsl.pipeline(name=\"train-endpoint-deploy\" + TIMESTAMP)\n",
    "def pipeline(\n",
    "    project: str = PROJECT_ID,\n",
    "    model_display_name: str = MODEL_DISPLAY_NAME,\n",
    "    serving_container_image_uri: str = \"us-docker.pkg.dev/cloud-aiplatform/prediction/tf2-cpu.2-3:latest\",\n",
    "):\n",
    "\n",
    "    train_task = initiate(\"model training\")\n",
    "    # https://github.com/kubeflow/pipelines/blob/master/sdk/python/kfp/v2/google/experimental/custom_job.py\n",
    "    experimental.run_as_aiplatform_custom_job(\n",
    "        train_task,\n",
    "        worker_pool_specs=[\n",
    "            {\n",
    "                \"containerSpec\": {\n",
    "                    \"args\": [],\n",
    "                    \"env\": [{\"name\": \"AIP_MODEL_DIR\",          \"value\": WORKING_DIR},\n",
    "                            {\"name\": \"AIP_CHECKPOINT_DIR\",     \"value\": WORKING_DIR},\n",
    "                            {\"name\": \"AIP_TENSORBOARD_LOG_DIR\",\"value\": WORKING_DIR},\n",
    "                            {\"name\": \"AIP_DATA_FORMAT\",        \"value\": \"csv\"},\n",
    "                            {\"name\": \"AIP_TRAINING_DATA_URI\",  \"value\": \"uri\"},\n",
    "                            {\"name\": \"AIP_VALIDATION_DATA_URI\",\"value\": \"uri\"},\n",
    "                            {\"name\": \"AIP_TEST_DATA_URI\",      \"value\": \"uri\"}],\n",
    "                    \"imageUri\": IMAGE_URI,\n",
    "                },\n",
    "                \"replicaCount\": \"1\",\n",
    "                \"machineSpec\": {\n",
    "                    \"machineType\": \"n1-standard-16\",\n",
    "                    #\"accelerator_type\": aip.gapic.AcceleratorType.NVIDIA_TESLA_K80,\n",
    "                    #\"accelerator_count\": 2,\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    model_upload_op = gcc_aip.ModelUploadOp(\n",
    "        project=project,\n",
    "        display_name=model_display_name,\n",
    "        artifact_uri=WORKING_DIR,\n",
    "        serving_container_image_uri=serving_container_image_uri,\n",
    "        serving_container_environment_variables={\"NOT_USED\": \"NO_VALUE\"},\n",
    "    )\n",
    "    model_upload_op.after(train_task)\n",
    "\n",
    "    endpoint_create_op = gcc_aip.EndpointCreateOp(\n",
    "        project=project,\n",
    "        display_name=\"pipelines-created-endpoint\",\n",
    "    )\n",
    "\n",
    "    model_deploy_op = gcc_aip.ModelDeployOp(  # noqa: F841\n",
    "        project=project,\n",
    "        endpoint=endpoint_create_op.outputs[\"endpoint\"],\n",
    "        model=model_upload_op.outputs[\"model\"],\n",
    "        deployed_model_display_name=model_display_name,\n",
    "        machine_type=\"n1-standard-4\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49afaf1-1cb6-4c7e-bcc8-4eef71c9c086",
   "metadata": {},
   "source": [
    "### Compile the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ee6302b-99f2-4175-9d61-0c83c9b22900",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2 import compiler  # noqa: F811\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline,\n",
    "    package_path=\"Redbull_Classification_Pipeline.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860cdf4f-c05e-4c4e-82f9-6b188b62102b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8eace513-e3e9-4359-a306-84a06e58e326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/567299754976/locations/us-central1/pipelineJobs/train-endpoint-deploy2021-10-02-06-0410-20211002060804\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/567299754976/locations/us-central1/pipelineJobs/train-endpoint-deploy2021-10-02-06-0410-20211002060804')\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/train-endpoint-deploy2021-10-02-06-0410-20211002060804?project=567299754976\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/567299754976/locations/us-central1/pipelineJobs/train-endpoint-deploy2021-10-02-06-0410-20211002060804 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/567299754976/locations/us-central1/pipelineJobs/train-endpoint-deploy2021-10-02-06-0410-20211002060804 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/567299754976/locations/us-central1/pipelineJobs/train-endpoint-deploy2021-10-02-06-0410-20211002060804 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/567299754976/locations/us-central1/pipelineJobs/train-endpoint-deploy2021-10-02-06-0410-20211002060804 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/567299754976/locations/us-central1/pipelineJobs/train-endpoint-deploy2021-10-02-06-0410-20211002060804 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/567299754976/locations/us-central1/pipelineJobs/train-endpoint-deploy2021-10-02-06-0410-20211002060804 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/567299754976/locations/us-central1/pipelineJobs/train-endpoint-deploy2021-10-02-06-0410-20211002060804 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/567299754976/locations/us-central1/pipelineJobs/train-endpoint-deploy2021-10-02-06-0410-20211002060804 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/567299754976/locations/us-central1/pipelineJobs/train-endpoint-deploy2021-10-02-06-0410-20211002060804 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob run completed. Resource name: projects/567299754976/locations/us-central1/pipelineJobs/train-endpoint-deploy2021-10-02-06-0410-20211002060804\n"
     ]
    }
   ],
   "source": [
    "DISPLAY_NAME = \"Redbull-pipeline-\" + TIMESTAMP\n",
    "\n",
    "job = aip.PipelineJob(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    template_path=\"Redbull_Classification_Pipeline.json\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "\n",
    "job.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649ad0c1-4e01-4251-8d76-7a6f959de7f1",
   "metadata": {},
   "source": [
    "### Cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "79e93f74-0cbc-4cd0-a87a-2ee52a981b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "'str' object has no attribute '_latest_future'\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/#1633154906609986...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/#1633154907792370...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/2021-10-02-06-0410.data-00000-of-00001#1633155342678344...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/2021-10-02-06-0410.index#1633155343780340...\n",
      "/ [4 objects]                                                                   \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m rm ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/2021-10-02-06-0410/#1633155174649422...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/2021-10-02-06-0410/assets/#1633155531741548...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/2021-10-02-06-0410/explanation_metadata.json#1633155535705133...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/2021-10-02-06-0410/saved_model.pb#1633155534483532...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/2021-10-02-06-0410/train/#1633155176194677...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/2021-10-02-06-0410/train/events.out.tfevents.1633155176.cmle-training-5894817988984867067.1.22164.v2#1633155327514988...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/2021-10-02-06-0410/train/events.out.tfevents.1633155204.cmle-training-5894817988984867067.profile-empty#1633155205401146...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/2021-10-02-06-0410/train/plugins/#1633155200466765...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/2021-10-02-06-0410/train/plugins/profile/#1633155202778602...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/2021-10-02-06-0410/train/plugins/profile/2021_10_02_06_13_15/#1633155204668709...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/2021-10-02-06-0410/train/plugins/profile/2021_10_02_06_13_15/cmle-training-5894817988984867067.input_pipeline.pb#1633155212904422...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/2021-10-02-06-0410/train/plugins/profile/2021_10_02_06_13_15/cmle-training-5894817988984867067.kernel_stats.pb#1633155214964039...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/2021-10-02-06-0410/train/plugins/profile/2021_10_02_06_13_15/cmle-training-5894817988984867067.memory_profile.json.gz#1633155208786498...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/2021-10-02-06-0410/train/plugins/profile/2021_10_02_06_13_15/cmle-training-5894817988984867067.overview_page.pb#1633155211969360...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/2021-10-02-06-0410/train/plugins/profile/2021_10_02_06_13_15/cmle-training-5894817988984867067.tensorflow_stats.pb#1633155214529263...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/2021-10-02-06-0410/train/plugins/profile/2021_10_02_06_13_15/cmle-training-5894817988984867067.trace.json.gz#1633155206464348...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/2021-10-02-06-0410/train/plugins/profile/2021_10_02_06_13_15/cmle-training-5894817988984867067.xplane.pb#1633155211396583...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/2021-10-02-06-0410/validation/#1633155224278912...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/2021-10-02-06-0410/validation/events.out.tfevents.1633155224.cmle-training-5894817988984867067.1.39262.v2#1633155237490161...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/2021-10-02-06-0410/variables/#1633155510433754...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/2021-10-02-06-0410/variables/variables.data-00000-of-00001#1633155528777166...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/2021-10-02-06-0410/variables/variables.index#1633155529499871...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/567299754976/#1633154909714881...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/567299754976/train-endpoint-deploy2021-10-02-06-0410-20211002060804/#1633154911619070...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/567299754976/train-endpoint-deploy2021-10-02-06-0410-20211002060804/endpoint-create_-8684602543151513600/#1633154914529976...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/567299754976/train-endpoint-deploy2021-10-02-06-0410-20211002060804/endpoint-create_-8684602543151513600/executor_output.json#1633154918499416...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/567299754976/train-endpoint-deploy2021-10-02-06-0410-20211002060804/model-deploy_-4072916524724125696/#1633156274118979...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/567299754976/train-endpoint-deploy2021-10-02-06-0410-20211002060804/model-deploy_-4072916524724125696/executor_output.json#1633156279384012...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/567299754976/train-endpoint-deploy2021-10-02-06-0410-20211002060804/model-upload_2844612502916956160/#1633155609526271...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/567299754976/train-endpoint-deploy2021-10-02-06-0410-20211002060804/model-upload_2844612502916956160/executor_output.json#1633155614859432...\n",
      "Removing gs://pipeline-2021-10-02-06-0410/pipeline_root/redbull/checkpoint#1633155345539573...\n",
      "/ [35 objects]                                                                  \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m rm ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "\n",
      "Operation completed over 35 objects.                                             \n",
      "Removing gs://pipeline-2021-10-02-06-0410/...\n"
     ]
    }
   ],
   "source": [
    "delete_dataset = True\n",
    "delete_pipeline = True\n",
    "delete_model = True\n",
    "delete_endpoint = True\n",
    "delete_batchjob = True\n",
    "delete_customjob = True\n",
    "delete_hptjob = True\n",
    "delete_bucket = True\n",
    "\n",
    "try:\n",
    "    if delete_model and \"DISPLAY_NAME\" in globals():\n",
    "        models = aip.Model.list(\n",
    "            filter=f\"display_name={DISPLAY_NAME}\", order_by=\"create_time\"\n",
    "        )\n",
    "        model = models[0]\n",
    "        aip.Model.delete(model)\n",
    "        print(\"Deleted model:\", model)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    if delete_endpoint and \"DISPLAY_NAME\" in globals():\n",
    "        endpoints = aip.Endpoint.list(\n",
    "            filter=f\"display_name={DISPLAY_NAME}_endpoint\", order_by=\"create_time\"\n",
    "        )\n",
    "        endpoint = endpoints[0]\n",
    "        endpoint.undeploy_all()\n",
    "        aip.Endpoint.delete(endpoint.resource_name)\n",
    "        print(\"Deleted endpoint:\", endpoint)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "if delete_dataset and \"DISPLAY_NAME\" in globals():\n",
    "    if \"tabular\" == \"tabular\":\n",
    "        try:\n",
    "            datasets = aip.TabularDataset.list(\n",
    "                filter=f\"display_name={DISPLAY_NAME}\", order_by=\"create_time\"\n",
    "            )\n",
    "            dataset = datasets[0]\n",
    "            aip.TabularDataset.delete(dataset.resource_name)\n",
    "            print(\"Deleted dataset:\", dataset)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    if \"tabular\" == \"image\":\n",
    "        try:\n",
    "            datasets = aip.ImageDataset.list(\n",
    "                filter=f\"display_name={DISPLAY_NAME}\", order_by=\"create_time\"\n",
    "            )\n",
    "            dataset = datasets[0]\n",
    "            aip.ImageDataset.delete(dataset.resource_name)\n",
    "            print(\"Deleted dataset:\", dataset)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    if \"tabular\" == \"text\":\n",
    "        try:\n",
    "            datasets = aip.TextDataset.list(\n",
    "                filter=f\"display_name={DISPLAY_NAME}\", order_by=\"create_time\"\n",
    "            )\n",
    "            dataset = datasets[0]\n",
    "            aip.TextDataset.delete(dataset.resource_name)\n",
    "            print(\"Deleted dataset:\", dataset)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    if \"tabular\" == \"video\":\n",
    "        try:\n",
    "            datasets = aip.VideoDataset.list(\n",
    "                filter=f\"display_name={DISPLAY_NAME}\", order_by=\"create_time\"\n",
    "            )\n",
    "            dataset = datasets[0]\n",
    "            aip.VideoDataset.delete(dataset.resource_name)\n",
    "            print(\"Deleted dataset:\", dataset)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "try:\n",
    "    if delete_pipeline and \"DISPLAY_NAME\" in globals():\n",
    "        pipelines = aip.PipelineJob.list(\n",
    "            filter=f\"display_name={DISPLAY_NAME}\", order_by=\"create_time\"\n",
    "        )\n",
    "        pipeline = pipelines[0]\n",
    "        aip.PipelineJob.delete(pipeline.resource_name)\n",
    "        print(\"Deleted pipeline:\", pipeline)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "if delete_bucket and \"BUCKET_NAME\" in globals():\n",
    "    ! gsutil rm -r $BUCKET_NAME"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m80"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
