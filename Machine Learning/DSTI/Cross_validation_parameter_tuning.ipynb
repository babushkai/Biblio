{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Cross_validation_parameter_tuning.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOT7zFDatIbvesFs6f/ityT"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"a701HLRyDMRl"},"source":["'''To implement K-fold cross-validation, we use a scikit_learn wrapper in Keras: KerasClassifier. \n","In other words, we use Keras to build the model and use scikit_learn for cross-validation. '''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tYvG7Ic1DTyH"},"source":["import tensorflow as tf\n","from numpy import mean\n","from numpy import std\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import accuracy_score\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.model_selection import cross_val_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OXt5ZDOJDdX0"},"source":["def build_classifier(optimizer):\n","  model = tf.keras.models.Sequential()\n","  model.add(tf.keras.layers.Dense(units = 10, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n","  model.add(tf.keras.layers.Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n","  model.add(tf.keras.layers.Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n","  model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n","  return model\n","\n","my_model = KerasClassifier(build_fn = build_classifier)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AiCpLXi8DmiG"},"source":["# create dataset\n","import pandas as pd\n","dataset = pd.read_csv('Churn_Modelling.csv')  \n","X = dataset.iloc[:, 3: 13].values\n","y = dataset.iloc[:, 13].values\n","\n","from sklearn.preprocessing import LabelEncoder\n","labelencoder_X_1 = LabelEncoder() #instantiate an object of the class LabelEncoder\n","X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1]) #ordinal encoding for column 1\n","\n","labelencoder_X_2 = LabelEncoder()\n","X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2]) #ordinal encoding for column 2\n","\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","import numpy as np\n","ct = ColumnTransformer( #'encoder' is the name of the column transformer\n","    [('encoder', OneHotEncoder(), [1])],    # The column numbers to be transformed (here is [1] but can be [0, 1, 3])\n","    remainder='passthrough'                         # Leave the rest of the columns untouched\n",")\n","X = np.array(ct.fit_transform(X), dtype=np.float)\n","\n","X = X[:, 1:]\n","\n","#Standardise the data (x_standardised = (x - x_mean)/std_dev)\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","'''X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test) #note that we use the scale set from the training set to transform the test set'''\n","X = sc.fit_transform(X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1p6W_MoxDqin"},"source":["parameters = {'batch_size': [20, 30], 'nb_epoch': [50, 100], 'optimizer': ['adam', 'sgd']}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UMTxm5phEBTq"},"source":["grid_search = GridSearchCV(estimator=my_model, param_grid=parameters, scoring = 'accuracy', cv = 10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4WEltzmcEFCg","executionInfo":{"status":"ok","timestamp":1614288262953,"user_tz":-60,"elapsed":72324,"user":{"displayName":"Vera DAMERJIAN PIETERS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_gM1OlZjMxOZzc-1zQnPZ0v5koi85ABiRK5fq=s64","userId":"04505436796132546123"}},"outputId":"3d4bd703-d80f-4d67-c287-9275efda0583"},"source":["grid_search = grid_search.fit(X, y)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["450/450 [==============================] - 1s 1ms/step - loss: 0.6026 - accuracy: 0.7899\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["450/450 [==============================] - 1s 1ms/step - loss: 0.6133 - accuracy: 0.7825\n","450/450 [==============================] - 1s 956us/step - loss: 0.6041 - accuracy: 0.7983\n","450/450 [==============================] - 1s 1ms/step - loss: 0.6641 - accuracy: 0.7867\n","450/450 [==============================] - 1s 972us/step - loss: 0.6252 - accuracy: 0.7908\n","450/450 [==============================] - 1s 953us/step - loss: 0.6008 - accuracy: 0.7824\n","450/450 [==============================] - 1s 963us/step - loss: 0.6020 - accuracy: 0.7835\n","450/450 [==============================] - 1s 995us/step - loss: 0.5875 - accuracy: 0.7937\n","450/450 [==============================] - 1s 975us/step - loss: 0.6055 - accuracy: 0.7874\n","450/450 [==============================] - 1s 979us/step - loss: 0.5967 - accuracy: 0.7897\n","450/450 [==============================] - 1s 935us/step - loss: 0.6281 - accuracy: 0.7899\n","450/450 [==============================] - 1s 950us/step - loss: 0.6267 - accuracy: 0.7948\n","450/450 [==============================] - 1s 926us/step - loss: 0.6283 - accuracy: 0.7969\n","450/450 [==============================] - 1s 936us/step - loss: 0.6257 - accuracy: 0.7998\n","450/450 [==============================] - 1s 922us/step - loss: 0.6294 - accuracy: 0.7897\n","450/450 [==============================] - 1s 948us/step - loss: 0.6298 - accuracy: 0.7904\n","450/450 [==============================] - 1s 952us/step - loss: 0.6290 - accuracy: 0.7924\n","450/450 [==============================] - 1s 894us/step - loss: 0.6284 - accuracy: 0.7908\n","450/450 [==============================] - 1s 956us/step - loss: 0.6274 - accuracy: 0.7897\n","450/450 [==============================] - 1s 936us/step - loss: 0.6296 - accuracy: 0.7891\n","450/450 [==============================] - 1s 985us/step - loss: 0.6075 - accuracy: 0.7832\n","450/450 [==============================] - 1s 991us/step - loss: 0.5972 - accuracy: 0.7878\n","450/450 [==============================] - 1s 984us/step - loss: 0.6095 - accuracy: 0.7899\n","450/450 [==============================] - 1s 971us/step - loss: 0.6168 - accuracy: 0.7900\n","450/450 [==============================] - 1s 982us/step - loss: 0.5973 - accuracy: 0.7873\n","450/450 [==============================] - 1s 961us/step - loss: 0.6005 - accuracy: 0.7946\n","450/450 [==============================] - 1s 955us/step - loss: 0.5941 - accuracy: 0.7931\n","450/450 [==============================] - 1s 965us/step - loss: 0.5997 - accuracy: 0.7841\n","450/450 [==============================] - 1s 993us/step - loss: 0.6105 - accuracy: 0.7979\n","450/450 [==============================] - 1s 1ms/step - loss: 0.6029 - accuracy: 0.7855\n","450/450 [==============================] - 1s 949us/step - loss: 0.6272 - accuracy: 0.8019\n","450/450 [==============================] - 1s 894us/step - loss: 0.6286 - accuracy: 0.7939\n","450/450 [==============================] - 1s 976us/step - loss: 0.6274 - accuracy: 0.7971\n","450/450 [==============================] - 1s 935us/step - loss: 0.6272 - accuracy: 0.7981\n","450/450 [==============================] - 1s 951us/step - loss: 0.6282 - accuracy: 0.7943\n","450/450 [==============================] - 1s 974us/step - loss: 0.6269 - accuracy: 0.7917\n","450/450 [==============================] - 1s 976us/step - loss: 0.6282 - accuracy: 0.7886\n","450/450 [==============================] - 1s 959us/step - loss: 0.6271 - accuracy: 0.7975\n","450/450 [==============================] - 1s 941us/step - loss: 0.6277 - accuracy: 0.7902\n","450/450 [==============================] - 1s 937us/step - loss: 0.6297 - accuracy: 0.7815\n","300/300 [==============================] - 1s 1ms/step - loss: 0.6548 - accuracy: 0.7938\n","300/300 [==============================] - 1s 1ms/step - loss: 0.6355 - accuracy: 0.7791\n","300/300 [==============================] - 1s 984us/step - loss: 0.6346 - accuracy: 0.7881\n","300/300 [==============================] - 1s 961us/step - loss: 0.6232 - accuracy: 0.7901\n","300/300 [==============================] - 1s 1ms/step - loss: 0.6374 - accuracy: 0.7789\n","300/300 [==============================] - 1s 980us/step - loss: 0.6417 - accuracy: 0.7941\n","300/300 [==============================] - 1s 1ms/step - loss: 0.6293 - accuracy: 0.8052\n","300/300 [==============================] - 1s 998us/step - loss: 0.6377 - accuracy: 0.7981\n","300/300 [==============================] - 1s 982us/step - loss: 0.6368 - accuracy: 0.7965\n","300/300 [==============================] - 1s 972us/step - loss: 0.6278 - accuracy: 0.7925\n","300/300 [==============================] - 1s 953us/step - loss: 0.6429 - accuracy: 0.7882\n","300/300 [==============================] - 1s 978us/step - loss: 0.6433 - accuracy: 0.7955\n","300/300 [==============================] - 1s 933us/step - loss: 0.6432 - accuracy: 0.7991\n","300/300 [==============================] - 1s 946us/step - loss: 0.6432 - accuracy: 0.7921\n","300/300 [==============================] - 1s 1ms/step - loss: 0.6439 - accuracy: 0.7819\n","300/300 [==============================] - 1s 960us/step - loss: 0.6449 - accuracy: 0.7894\n","300/300 [==============================] - 1s 971us/step - loss: 0.6446 - accuracy: 0.7860\n","300/300 [==============================] - 1s 911us/step - loss: 0.6441 - accuracy: 0.7959\n","300/300 [==============================] - 1s 952us/step - loss: 0.6443 - accuracy: 0.7948\n","300/300 [==============================] - 1s 930us/step - loss: 0.6459 - accuracy: 0.7829\n","300/300 [==============================] - 1s 962us/step - loss: 0.6308 - accuracy: 0.7911\n","300/300 [==============================] - 1s 972us/step - loss: 0.6339 - accuracy: 0.7816\n","300/300 [==============================] - 1s 1ms/step - loss: 0.6730 - accuracy: 0.7825\n","300/300 [==============================] - 1s 977us/step - loss: 0.6449 - accuracy: 0.7847\n","300/300 [==============================] - 1s 1ms/step - loss: 0.6218 - accuracy: 0.7871\n","300/300 [==============================] - 1s 1ms/step - loss: 0.6341 - accuracy: 0.7883\n","300/300 [==============================] - 1s 968us/step - loss: 0.6426 - accuracy: 0.7816\n","300/300 [==============================] - 1s 982us/step - loss: 0.6282 - accuracy: 0.7799\n","300/300 [==============================] - 1s 980us/step - loss: 0.6332 - accuracy: 0.7989\n","300/300 [==============================] - 1s 1ms/step - loss: 0.6409 - accuracy: 0.7814\n","300/300 [==============================] - 1s 936us/step - loss: 0.6445 - accuracy: 0.7846\n","300/300 [==============================] - 1s 942us/step - loss: 0.6444 - accuracy: 0.7891\n","300/300 [==============================] - 1s 973us/step - loss: 0.6425 - accuracy: 0.7951\n","300/300 [==============================] - 1s 1ms/step - loss: 0.6437 - accuracy: 0.7958\n","300/300 [==============================] - 1s 942us/step - loss: 0.6438 - accuracy: 0.7991\n","300/300 [==============================] - 1s 942us/step - loss: 0.6444 - accuracy: 0.7907\n","300/300 [==============================] - 1s 950us/step - loss: 0.6449 - accuracy: 0.7895\n","300/300 [==============================] - 1s 981us/step - loss: 0.6436 - accuracy: 0.7928\n","300/300 [==============================] - 1s 1ms/step - loss: 0.6427 - accuracy: 0.7971\n","300/300 [==============================] - 1s 960us/step - loss: 0.6435 - accuracy: 0.7932\n","500/500 [==============================] - 1s 990us/step - loss: 0.5969 - accuracy: 0.7858\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ufzAWHFVEMcO","executionInfo":{"status":"ok","timestamp":1614288369266,"user_tz":-60,"elapsed":1025,"user":{"displayName":"Vera DAMERJIAN PIETERS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_gM1OlZjMxOZzc-1zQnPZ0v5koi85ABiRK5fq=s64","userId":"04505436796132546123"}},"outputId":"b509149d-b9ff-4176-a6e7-9adb504ed344"},"source":["best_parameters = grid_search.best_params_\n","best_accuracy = grid_search.best_score_\n","\n","print(best_parameters)\n","print(best_accuracy)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'batch_size': 20, 'nb_epoch': 50, 'optimizer': 'adam'}\n","0.7962999999999999\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_7bht4ffFfx2"},"source":[""],"execution_count":null,"outputs":[]}]}