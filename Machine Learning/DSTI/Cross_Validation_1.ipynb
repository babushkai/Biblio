{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Cross_Validation_1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPpNqZcJL3ImTXXUDcBlLco"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"4tSPVi4I2kf2"},"source":["import pandas as pd\n","dataset = pd.read_csv('Churn_Modelling.csv')  \n","X = dataset.iloc[:, 3: 13].values\n","y = dataset.iloc[:, 13].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kbnbOHrp3B1I"},"source":["from sklearn.preprocessing import LabelEncoder\n","labelencoder_X_1 = LabelEncoder() #instantiate an object of the class LabelEncoder\n","X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1]) #ordinal encoding for column 1\n","\n","labelencoder_X_2 = LabelEncoder()\n","X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2]) #ordinal encoding for column 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"muZ37OPc3JLR"},"source":["from sklearn.preprocessing import OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","import numpy as np\n","ct = ColumnTransformer( #'encoder' is the name of the column transformer\n","    [('encoder', OneHotEncoder(), [1])],    # The column numbers to be transformed (here is [1] but can be [0, 1, 3])\n","    remainder='passthrough'                         # Leave the rest of the columns untouched\n",")\n","X = np.array(ct.fit_transform(X), dtype=np.float)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Rhcxa3A3Ox0"},"source":["X = X[:, 1:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h0ZsVnuy3Xaz"},"source":["'''from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.2, random_state = 10) # We use random_state to make sure splitting contains the same data each time.\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_eoLFFgj3cXo"},"source":["#Standardise the data (x_standardised = (x - x_mean)/std_dev)\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","'''X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test) #note that we use the scale set from the training set to transform the test set'''\n","X = sc.fit_transform(X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d63UFeDX3hyv"},"source":["import tensorflow as tf\n","\n","def create_model():\n","  model = tf.keras.models.Sequential()\n","\n","  #add input layer and first hidden layer\n","  model.add(tf.keras.layers.Dense(units=6, kernel_initializer='uniform', activation='relu'))\n","\n","  #add 2nd hidden layer\n","  model.add(tf.keras.layers.Dense(units=6, kernel_initializer='uniform', activation='relu'))\n","\n","  #output layer\n","  model.add(tf.keras.layers.Dense(units=1, kernel_initializer='uniform', activation='sigmoid')) #Sigmoid for binary, Softmax for multiclass\n","  \n","  model.compile(optimizer = 'adam', loss ='binary_crossentropy', metrics = ['accuracy'])\n","  \n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5yyA5EUh4-JT","executionInfo":{"status":"ok","timestamp":1614267755377,"user_tz":-60,"elapsed":18241,"user":{"displayName":"Vera DAMERJIAN PIETERS","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_gM1OlZjMxOZzc-1zQnPZ0v5koi85ABiRK5fq=s64","userId":"04505436796132546123"}},"outputId":"1ed41532-e75f-4c85-c1c0-cfb15be1cfcf"},"source":["from sklearn.model_selection import KFold\n","\n","n_split = 4\n","\n","for train_index,test_index in KFold(n_split).split(X):\n","  x_train, x_test = X[train_index], X[test_index]\n","  y_train, y_test = y[train_index], y[test_index]\n","  \n","  model = create_model()\n","  model.fit(x_train, y_train, epochs=20, verbose=0)\n","  \n","  print('Model evaluation ', model.evaluate(x_test,y_test))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["79/79 [==============================] - 0s 943us/step - loss: 0.4168 - accuracy: 0.8224\n","Model evaluation  [0.4168182611465454, 0.8223999738693237]\n","79/79 [==============================] - 0s 923us/step - loss: 0.4137 - accuracy: 0.8308\n","Model evaluation  [0.41374877095222473, 0.8307999968528748]\n","79/79 [==============================] - 0s 903us/step - loss: 0.3525 - accuracy: 0.8608\n","Model evaluation  [0.35245200991630554, 0.86080002784729]\n","79/79 [==============================] - 0s 1ms/step - loss: 0.4066 - accuracy: 0.8340\n","Model evaluation  [0.4066431522369385, 0.8339999914169312]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CJnxcTFM3uRI"},"source":[""],"execution_count":null,"outputs":[]}]}